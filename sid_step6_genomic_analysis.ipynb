{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SID Genetics Study Step 6: Genomic Analysis\n",
    "\n",
    "## Objective\n",
    "The purpose of this notebook is to run analyses on genetic data as part of a study on genetic predictors of statin-induced diabetes. These analyses include:\n",
    "\n",
    "**Candidate variant study**: takes variants that have known associations with statin on-target LDL-C lowering and finds their associations with new-onset diabetes\n",
    "- Variants tested: HMGCR (rs17238484, rs12916), LPA (rs10455872), SLC01B1 (rs4149056), APOE2 (rs7412), and APOE4 (rs429358)\n",
    "- Statistical methods: stratified + adjusted Cox regression model, interaction test (Cochran's Q)\n",
    "- Subsets tested: intention-to-treat, ≥30% decrease in LDL-C, per protocol, self-identified white\n",
    "\n",
    "**Mini polygenic score (PS)**: takes the six candidate variants and combines their effect sizes into a \"mini\" PS for each participant\n",
    "- Statistical methods: stratified + adjusted Cox regression model, interaction test (Cochran's Q)\n",
    "- Subset tested: intention-to-treat\n",
    "\n",
    "**Genome-wide Association Study (GWAS)**: uses All of Us' microarray data to find variants with genome-wide significant associations with statin induced diabetes\n",
    "- Statistical methods: stratified + adjusted Cox regression model (using Regenie 4.1's time-to-event model), interaction test (Cochran's Q)\n",
    "- Subsets tested: intention-to-treat, ≥30% decrease in LDL-C, per protocol, self-identified white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: To load necessary packages + their citations and pull in data frames generated in previous notebooks necessary for genetic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages('allofus')\n",
    "# install.packages('tidyverse')\n",
    "# install.packages('stats')\n",
    "# install.packages('survival')\n",
    "# install.packages('survminer')\n",
    "# install.packages('qqman')\n",
    "# install.packages('tableone')\n",
    "# install.packages(\"cowplot\")\n",
    "# install.packages(\"tableone\")\n",
    "# install.packages('gridExtra')\n",
    "\n",
    "library(allofus)\n",
    "library(tidyverse)\n",
    "library(stats)\n",
    "library(survival)\n",
    "library(survminer)\n",
    "library(qqman)\n",
    "library(tableone)\n",
    "library(ggplot2)\n",
    "library(cowplot)\n",
    "library(gridExtra)\n",
    "\n",
    "my_bucket <- Sys.getenv('WORKSPACE_BUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Package citations\n",
    "citation(\"allofus\")\n",
    "citation(\"tidyverse\")\n",
    "citation(\"stats\")\n",
    "citation(\"survival\")\n",
    "citation(\"survminer\")\n",
    "citation(\"qqman\")\n",
    "citation(\"tableone\")\n",
    "citation(\"ggplot2\")\n",
    "citation(\"cowplot\")\n",
    "citation(\"gridExtra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pull in data frames for each subset\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_pheno_files/\", \"itt_df_v2.csv\", \" .\"), intern=T)\n",
    "itt_df <- read.csv(\"itt_df_v2.csv\")\n",
    "\n",
    "dim(itt_df)\n",
    "# head(itt_df)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_pheno_files/\", \"ldl30_df_v2.csv\", \" .\"), intern=T)\n",
    "ldl30_df <- read.csv(\"ldl30_df_v2.csv\")\n",
    "\n",
    "dim(ldl30_df)\n",
    "# head(ldl30_df)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_pheno_files/\", \"ldl_df_v3.csv\", \" .\"), intern=T)\n",
    "ldl30_df2 <- read.csv(\"ldl_df_v3.csv\")\n",
    "\n",
    "dim(ldl30_df2)\n",
    "# head(ldl30_df2)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_pheno_files/\", \"per_protocol_df_v2.csv\", \" .\"), intern=T)\n",
    "per_protocol_df <- read.csv(\"per_protocol_df_v2.csv\")\n",
    "\n",
    "dim(per_protocol_df)\n",
    "# head(per_protocol_df)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_pheno_files/\", \"white_df_v2.csv\", \" .\"), intern=T)\n",
    "white_df <- read.csv(\"white_df_v2.csv\")\n",
    "\n",
    "dim(white_df)\n",
    "# head(white_df)\n",
    "\n",
    "# LDL-C Analysis data frame\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_pheno_files/\", \"ldl_df_v3.csv\", \" .\"), intern=T)\n",
    "ldl_df <- read.csv(\"ldl_df_v3.csv\")\n",
    "\n",
    "dim(ldl_df)\n",
    "# head(ldl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pull in candidate variant data frames\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/candidate/\", \"sid_targets_chr5.raw\", \" .\"), intern=T)\n",
    "sid_targets_chr5 <- read_table(\"sid_targets_chr5.raw\") %>% select(-c(PAT, MAT, SEX, PHENOTYPE))\n",
    "\n",
    "dim(sid_targets_chr5)\n",
    "# head(sid_targets_chr5)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/candidate/\", \"sid_targets_chr6.raw\", \" .\"), intern=T)\n",
    "sid_targets_chr6 <- read_table(\"sid_targets_chr6.raw\") %>% select(-c(PAT, MAT, SEX, PHENOTYPE))\n",
    "\n",
    "dim(sid_targets_chr6)\n",
    "# head(sid_targets_chr6)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/candidate/\", \"sid_targets_chr12.raw\", \" .\"), intern=T)\n",
    "sid_targets_chr12 <- read_table(\"sid_targets_chr12.raw\") %>% select(-c(PAT, MAT, SEX, PHENOTYPE))\n",
    "\n",
    "dim(sid_targets_chr12)\n",
    "# head(sid_targets_chr12)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/candidate/\", \"sid_targets_chr19.raw\", \" .\"), intern=T)\n",
    "sid_targets_chr19 <- read_table(\"sid_targets_chr19.raw\") %>% select(-c(PAT, MAT, SEX, PHENOTYPE))\n",
    "\n",
    "dim(sid_targets_chr19)\n",
    "# head(sid_targets_chr19)\n",
    "\n",
    "# Merge candidate variant data frames\n",
    "sid_targets <- full_join(sid_targets_chr5, sid_targets_chr6) %>%\n",
    "                full_join(sid_targets_chr12) %>%\n",
    "                full_join(sid_targets_chr19) %>%\n",
    "                rename(rs17238484 = \"chr5:75352671:G:T_G\",\n",
    "                       rs12916 = \"chr5:75360714:T:C_T\",\n",
    "                       rs10455872 = \"chr6:160589086:A:G_A\",\n",
    "                       rs4149056 = \"chr12:21178615:T:C_T\",\n",
    "                       rs7412 = \"chr19:44908822:C:T_C\",\n",
    "                       rs429358 = \"chr19:44908684:T:C_T\") %>%\n",
    "                mutate(rs7412_swap = case_when(rs7412 == 2 ~ 0,\n",
    "                                               rs7412 == 1 ~ 1,\n",
    "                                               rs7412 == 0 ~ 2),\n",
    "                      rs10455872_swap = case_when(rs10455872 == 2 ~ 0,\n",
    "                                               rs10455872 == 1 ~ 1,\n",
    "                                               rs10455872 == 0 ~ 2),\n",
    "                      rs429358_swap = case_when(rs429358 == 2 ~ 0,\n",
    "                                               rs429358 == 1 ~ 1,\n",
    "                                               rs429358 == 0 ~ 2))\n",
    "\n",
    "dim(sid_targets)\n",
    "head(sid_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pull in GWAS results - itt\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/arrays/itt/SID_GWAS_array_statin_itt_MAF1_step2_array_time.regenie\", \" .\"), intern=T)\n",
    "array_statin_itt_MAF1 <- read_table(\"SID_GWAS_array_statin_itt_MAF1_step2_array_time.regenie\")\n",
    "\n",
    "dim(array_statin_itt_MAF1)\n",
    "# head(array_statin_itt_MAF1)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/arrays/itt/SID_GWAS_array_nu_itt_MAF1_step2_array_time.regenie\", \" .\"), intern=T)\n",
    "array_nu_itt_MAF1 <- read_table(\"SID_GWAS_array_nu_itt_MAF1_step2_array_time.regenie\")\n",
    "\n",
    "dim(array_nu_itt_MAF1)\n",
    "# head(array_nu_itt_MAF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pull in GWAS results - ldl30\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/arrays/ldl30/SID_GWAS_array_statin_ldl30_MAF25_step2_array_time.regenie\", \" .\"), intern=T)\n",
    "array_statin_ldl30_MAF25 <- read_table(\"SID_GWAS_array_statin_ldl30_MAF25_step2_array_time.regenie\")\n",
    "\n",
    "dim(array_statin_ldl30_MAF25)\n",
    "# head(array_statin_ldl30_MAF25)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/arrays/ldl30/SID_GWAS_array_nu_ldl30_MAF25_step2_array_time.regenie\", \" .\"), intern=T)\n",
    "array_nu_ldl30_MAF25 <- read_table(\"SID_GWAS_array_nu_ldl30_MAF25_step2_array_time.regenie\")\n",
    "\n",
    "dim(array_nu_ldl30_MAF25)\n",
    "# head(array_nu_ldl30_MAF25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pull in GWAS results - per protocol\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/arrays/per_protocol/SID_GWAS_array_statin_per_protocol_MAF20_step2_array_time.regenie\", \" .\"), intern=T)\n",
    "array_statin_pp_MAF20 <- read_table(\"SID_GWAS_array_statin_per_protocol_MAF20_step2_array_time.regenie\")\n",
    "\n",
    "dim(array_statin_pp_MAF20)\n",
    "# head(array_statin_pp_MAF20)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/arrays/per_protocol/SID_GWAS_array_nu_per_protocol_MAF20_step2_array_time.regenie\", \" .\"), intern=T)\n",
    "array_nu_pp_MAF20 <- read_table(\"SID_GWAS_array_nu_per_protocol_MAF20_step2_array_time.regenie\")\n",
    "\n",
    "dim(array_nu_pp_MAF20)\n",
    "# head(array_nu_pp_MAF20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pull in GWAS results - self-identified white\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/arrays/white/SID_GWAS_array_statin_white_MAF1_step2_array_time.regenie\", \" .\"), intern=T)\n",
    "array_statin_white_MAF1 <- read_table(\"SID_GWAS_array_statin_white_MAF1_step2_array_time.regenie\")\n",
    "\n",
    "dim(array_statin_white_MAF1)\n",
    "# head(array_statin_white_MAF1)\n",
    "\n",
    "system(paste0(\"gsutil cp \", my_bucket, \"/sid_geno_files/arrays/white/SID_GWAS_array_nu_white_MAF1_step2_array_time.regenie\", \" .\"), intern=T)\n",
    "array_nu_white_MAF1 <- read_table(\"SID_GWAS_array_nu_white_MAF1_step2_array_time.regenie\")\n",
    "\n",
    "dim(array_nu_white_MAF1)\n",
    "# head(array_nu_white_MAF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions - Candidate + mini PS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: Create functions to streamline analysis of candidate variants and mini PS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate allele frequencies for each candidate variant\n",
    "allele_frequency <- function(df, snp_start, snp_end) {\n",
    "    \n",
    "    # Function to count categories and NAs for a single column\n",
    "    count_alleles <- function(column) {\n",
    "      counts <- table(factor(column, levels = c(0, 1, 2), exclude = NULL), useNA = \"always\")\n",
    "      counts <- as.data.frame(counts)\n",
    "      names(counts) <- c(\"allele\", \"count\")\n",
    "      counts$allele <- as.character(counts$allele)\n",
    "      counts$allele[is.na(counts$allele)] <- \"NA\"\n",
    "      return(counts)\n",
    "    }\n",
    "\n",
    "    # Apply the function to each column and combine results\n",
    "    allele_counts <- df %>%\n",
    "                        summarize(across(c(snp_start:snp_end), ~ list(count_alleles(.x)))) %>%\n",
    "                        pivot_longer(cols = everything(), names_to = \"allele_name\", values_to = \"counts\") %>%\n",
    "                        unnest(counts)\n",
    "\n",
    "    # Reshape the data frame for better readability\n",
    "    allele_counts <- allele_counts %>%\n",
    "                          pivot_wider(names_from = allele, values_from = count, values_fill = 0) %>%\n",
    "                          rename(RR = \"0\",\n",
    "                                 RA = \"1\",\n",
    "                                 AA = \"2\")\n",
    "                            \n",
    "    \n",
    "    # Find the allele frequencies for each allele\n",
    "    allele_counts <- allele_counts %>%\n",
    "                          mutate(ref_freq = (2*(RR)+RA)/(2*(RR+RA+AA)),\n",
    "                                 alt_freq = (2*(AA)+RA)/(2*(RR+RA+AA)))\n",
    "                        \n",
    "    \n",
    "    return(allele_counts)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to determine HR in each population for numeric variables (dosage or PS), split by treatment group\n",
    "var_association <- function(df, var) {\n",
    "    \n",
    "    # Initialize the outputed data frame\n",
    "    var_df <- data.frame(\n",
    "                group = character(),\n",
    "                variable = character(),\n",
    "                beta = numeric(),\n",
    "                HR = numeric(),\n",
    "                lower_ci_HR = numeric(),\n",
    "                upper_ci_HR = numeric(),\n",
    "                HR_SE = numeric(),\n",
    "                HR_p = numeric()      \n",
    "            )\n",
    "    \n",
    "    # Split input data frame by treatment group\n",
    "    grp_split <- split(\n",
    "        df,\n",
    "        df[,\"group\"],\n",
    "        drop = FALSE\n",
    "        )\n",
    "    \n",
    "    # Loop through split treatment group data frames\n",
    "    for (i in names(grp_split)) {\n",
    "        \n",
    "        # If running this analysis in self-identified white subset, exclude population covariate,\n",
    "        # else, include population covariate\n",
    "        if(all(df$population == \"White\")) {\n",
    "            \n",
    "            int_formula <- as.formula(paste0(\"Surv(time, status) ~ \", var, \" + index_age + sex_at_birth +\n",
    "                                    low_hdl + high_tg + high_bmi + smoking_status + htn_status + gd_status +\n",
    "                                    PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + \n",
    "                                    PC13 + PC14 + PC15 + PC16\"))\n",
    "            \n",
    "        } else {\n",
    "            \n",
    "            int_formula <- as.formula(paste0(\"Surv(time, status) ~ \", var, \" + index_age + population + sex_at_birth +\n",
    "                                    low_hdl + high_tg + high_bmi + smoking_status + htn_status + gd_status +\n",
    "                                    PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + \n",
    "                                    PC13 + PC14 + PC15 + PC16\"))\n",
    "            \n",
    "        }\n",
    "        \n",
    "        # Run model\n",
    "        int_m <- coxph(int_formula, data = grp_split[[i]])\n",
    "        \n",
    "        # Extract necessary outcomes from model output\n",
    "        grp <- i\n",
    "        var_name <- var\n",
    "        grp_beta <- coef(summary(int_m))[paste0(var), \"coef\"]\n",
    "        grp_HR <- coef(summary(int_m))[paste0(var), \"exp(coef)\"]\n",
    "        grp_lower <- exp(confint(int_m))[paste0(var), \"2.5 %\"]\n",
    "        grp_upper <- exp(confint(int_m))[paste0(var), \"97.5 %\"]\n",
    "        grp_SE <- coef(summary(int_m))[paste0(var), \"se(coef)\"]\n",
    "        grp_p <- coef(summary(int_m))[paste0(var), \"Pr(>|z|)\"]\n",
    "        \n",
    "        # Bind results to initialized data frame\n",
    "        var_df <- rbind(var_df, data.frame(\n",
    "                group = grp,\n",
    "                variable = var_name,\n",
    "                beta = grp_beta,\n",
    "                HR = grp_HR,\n",
    "                lower_ci_HR = grp_lower,\n",
    "                upper_ci_HR = grp_upper,\n",
    "                HR_SE = grp_SE,\n",
    "                HR_p = grp_p))\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return(var_df)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Put variants together into one data frame\n",
    "candidate_results <- function(df, snp_start, snp_end) {\n",
    "    \n",
    "    # Get index of first SNP and last\n",
    "    istart <- which(names(df) == snp_start)\n",
    "    iend <- which(names(df) == snp_end)\n",
    "    \n",
    "    # Initialize data frame to hold results for all variants\n",
    "    snp_df <- data.frame(\n",
    "                group = character(),\n",
    "                variable = character(),\n",
    "                beta = numeric(),\n",
    "                HR = numeric(),\n",
    "                lower_ci_HR = numeric(),\n",
    "                upper_ci_HR = numeric(),\n",
    "                HR_SE = numeric(),\n",
    "                HR_p = numeric()      \n",
    "            )\n",
    "    \n",
    "    # Bind data frames with results for each variant\n",
    "    for (snp in colnames(df[, istart:iend])) {\n",
    "        snp_df <- rbind(snp_df, var_association(df, snp))\n",
    "    }\n",
    "    \n",
    "    return(snp_df)\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate P of interaction\n",
    "\n",
    "p_int_calculator <- function(t_beta, t_se, c_beta, c_se) {\n",
    "    # Sample data\n",
    "    beta <- c(t_beta, c_beta)  # beta coefficients for each stratum\n",
    "    se <- c(t_se, c_se)   # standard errors for each stratum\n",
    "\n",
    "    # Calculate the weights for each stratum\n",
    "    weights <- 1 / (se^2)\n",
    "\n",
    "    # Calculate the weighted mean effect size\n",
    "    weighted_mean <- sum(weights * beta) / sum(weights)\n",
    "\n",
    "    # Calculate Cochran's Q\n",
    "    Q <- sum(weights * (beta - weighted_mean)^2)\n",
    "\n",
    "    # Degrees of freedom\n",
    "    df <- length(beta) - 1\n",
    "\n",
    "    # Calculate the p-value for Cochran's Q test\n",
    "    p_value <- pchisq(Q, df, lower.tail = FALSE)\n",
    "\n",
    "    # Print the results\n",
    "    return(p_value = p_value)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to create a data frame with all interaction test results\n",
    "int_test <- function(df, snp_df, snp_start, snp_end) {\n",
    "    \n",
    "    # Get index of first SNP and last\n",
    "    istart <- which(names(df) == snp_start)\n",
    "    iend <- which(names(df) == snp_end)\n",
    "    \n",
    "    # Initialize data frame to hold results\n",
    "    int_p_df <- data.frame(snp = character(), p_int_calc = numeric())\n",
    "    \n",
    "    # Loop through each SNP and generate P of interaction using calculator function\n",
    "    for (snp in colnames(df[, istart:iend])) {\n",
    "        \n",
    "        # Calculate P of interaction\n",
    "        calc_p <- p_int_calculator(snp_df[snp_df$variable == snp & snp_df$group == \"non-user\", \"beta\"], \n",
    "                                  snp_df[snp_df$variable == snp & snp_df$group == \"non-user\", \"HR_SE\"],\n",
    "                                  snp_df[snp_df$variable == snp & snp_df$group == \"user\", \"beta\"], \n",
    "                                  snp_df[snp_df$variable == snp & snp_df$group == \"user\", \"HR_SE\"])\n",
    "        \n",
    "        # Get variant name\n",
    "        snp_name <- snp\n",
    "        # Get P of interaction\n",
    "        grp_p_calc <- calc_p\n",
    "        \n",
    "        # Bind results to data frame\n",
    "        int_p_df <- rbind(int_p_df, data.frame(\n",
    "                            snp = snp_name,\n",
    "                            p_int_calc = grp_p_calc))\n",
    "        }\n",
    "    \n",
    "    return(int_p_df)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to determine HR in each PS quintile, split by treatment group\n",
    "psq_association <- function(df, quint, quintiles_vector) {\n",
    "    \n",
    "    # Initialize quintile data frame\n",
    "    quint_df <- data.frame(\n",
    "                group = character(),\n",
    "                quintile = character(),\n",
    "                HR = numeric(),\n",
    "                beta = numeric(),\n",
    "                lower_ci_HR = numeric(),\n",
    "                upper_ci_HR = numeric(),\n",
    "                HR_SE = numeric(),\n",
    "                HR_p = numeric()      \n",
    "            )\n",
    "    \n",
    "    # Split cohort by treatment group\n",
    "    grp_split <- split(\n",
    "        df,\n",
    "        df[,\"group\"],\n",
    "        drop = FALSE\n",
    "        )\n",
    "    \n",
    "    # Loop through both treatment groups\n",
    "    for (i in names(grp_split)) {\n",
    "        \n",
    "        # If running this analysis in self-identified white subset, exclude population covariate,\n",
    "        # else, include population covariate\n",
    "        if(all(df$population == \"White\")) {\n",
    "            \n",
    "            int_formula <- as.formula(paste0(\"Surv(time, status) ~ \", quint, \" + index_age + sex_at_birth +\n",
    "                                    low_hdl + high_tg + high_bmi + smoking_status + htn_status + gd_status +\n",
    "                                    PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + \n",
    "                                    PC13 + PC14 + PC15 + PC16\"))\n",
    "            \n",
    "        } else {\n",
    "            \n",
    "            int_formula <- as.formula(paste0(\"Surv(time, status) ~ \", quint, \" + index_age + population + sex_at_birth +\n",
    "                                    low_hdl + high_tg + high_bmi + smoking_status + htn_status + gd_status +\n",
    "                                    PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + \n",
    "                                    PC13 + PC14 + PC15 + PC16\"))\n",
    "            \n",
    "        }\n",
    "        \n",
    "        # Run the interaction model\n",
    "        int_m <- coxph(int_formula, data = grp_split[[i]])\n",
    "        \n",
    "        # Extract necessary outputs from model summary for the second quintile\n",
    "        grp <- i\n",
    "        quint_name <- quintiles_vector[1]\n",
    "        grp_beta <- coef(summary(int_m))[quintiles_vector[1], \"coef\"]\n",
    "        grp_HR <- coef(summary(int_m))[quintiles_vector[1], \"exp(coef)\"]\n",
    "        grp_lower <- exp(confint(int_m))[quintiles_vector[1], \"2.5 %\"]\n",
    "        grp_upper <- exp(confint(int_m))[quintiles_vector[1], \"97.5 %\"]\n",
    "        grp_SE <- coef(summary(int_m))[quintiles_vector[1], \"se(coef)\"]\n",
    "        grp_p <- coef(summary(int_m))[quintiles_vector[1], \"Pr(>|z|)\"]\n",
    "        \n",
    "        # Bind outputs to initialize data frame \n",
    "        quint_df <- rbind(quint_df, data.frame(\n",
    "                group = grp,\n",
    "                quintile = quint_name,\n",
    "                HR = grp_HR,\n",
    "                beta = grp_beta,\n",
    "                lower_ci_HR = grp_lower,\n",
    "                upper_ci_HR = grp_upper,\n",
    "                HR_SE = grp_SE,\n",
    "                HR_p = grp_p))\n",
    "        \n",
    "        # Loop through the rest of the quintiles and bind extracted outputs to quintile data frame\n",
    "        for (q in quintiles_vector[seq(2,4)]) {\n",
    "            \n",
    "            grp <- i\n",
    "            quint_name <- q\n",
    "            grp_beta <- coef(summary(int_m))[q, \"coef\"]\n",
    "            grp_HR <- coef(summary(int_m))[q, \"exp(coef)\"]\n",
    "            grp_lower <- exp(confint(int_m))[q, \"2.5 %\"]\n",
    "            grp_upper <- exp(confint(int_m))[q, \"97.5 %\"]\n",
    "            grp_SE <- coef(summary(int_m))[q, \"se(coef)\"]\n",
    "            grp_p <- coef(summary(int_m))[q, \"Pr(>|z|)\"]\n",
    "        \n",
    "            quint_df <- rbind(quint_df, data.frame(\n",
    "                    group = grp,\n",
    "                    quintile = q,\n",
    "                    HR = grp_HR,\n",
    "                    beta = grp_beta,\n",
    "                    lower_ci_HR = grp_lower,\n",
    "                    upper_ci_HR = grp_upper,\n",
    "                    HR_SE = grp_SE,\n",
    "                    HR_p = grp_p))\n",
    "            \n",
    "        }\n",
    "        \n",
    "        \n",
    "    }\n",
    "    \n",
    "    return(quint_df)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this section is to model the association between NOD and six candidate variants that have demonstrated an effect on statin on-target LDL-C lowering. To do this, we first generate the hazard ratios (HR) for each variant in statin users and non-users separately, which gives us an estimate of the effect of the variant in each treatment group. Then, we use Cochran's Q test to find the heterogenity between the effect of the variant in statin users vs. non-users. If the P value for a variant is below a Boneferroni adjusted 0.008333 (adjusted for multiple comparisons for six variants), it is considered to have a significant interaction with NOD, and thus point to an association with statin-induced diabetes. A P-value of less than 0.05 is considered suggestive of a significant interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intention-to-treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prep data frame for itt subset\n",
    "itt_snp_df <- left_join(itt_df, sid_targets)\n",
    "\n",
    "dim(itt_snp_df)\n",
    "# head(itt_snp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate allele frequencies overall\n",
    "allele_frequency(itt_snp_df, \"rs17238484\", \"rs429358_swap\")\n",
    "\n",
    "# Calculate allele frequencies by NOD status (1 = NOD, 0 = no NOD)\n",
    "allele_frequency(itt_snp_df %>% filter(status == 1), \"rs17238484\", \"rs429358_swap\")\n",
    "allele_frequency(itt_snp_df %>% filter(status == 0), \"rs17238484\", \"rs429358_swap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate HRs for each SNP in each treatment group\n",
    "itt_int_snps <- candidate_results(itt_snp_df, \"rs17238484\", \"rs429358_swap\")\n",
    "itt_int_snps\n",
    "\n",
    "# Calculate the p-interaction with statins for each SNP\n",
    "int_test(itt_snp_df, itt_int_snps, \"rs17238484\", \"rs429358_swap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## ≥30% Decrease in LDL-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prep data frame for ≥30% decrease in LDL-C subset\n",
    "ldl30_snp_df <- left_join(ldl30_df, sid_targets)\n",
    "\n",
    "dim(ldl30_snp_df)\n",
    "# head(ldl30_snp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate allele frequencies overall\n",
    "allele_frequency(ldl30_snp_df, \"rs17238484\", \"rs429358_swap\")\n",
    "\n",
    "# Calculate allele frequencies by NOD status (1 = NOD, 0 = no NOD)\n",
    "allele_frequency(ldl30_snp_df %>% filter(status == 1), \"rs17238484\", \"rs429358_swap\")\n",
    "allele_frequency(ldl30_snp_df %>% filter(status == 0), \"rs17238484\", \"rs429358_swap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate HRs for each SNP in each treatment group\n",
    "ldl30_int_snps <- candidate_results(ldl30_snp_df, \"rs17238484\", \"rs429358_swap\")\n",
    "ldl30_int_snps\n",
    "\n",
    "# Calculate the p-interaction with statins for each SNP\n",
    "int_test(ldl30_snp_df, ldl30_int_snps, \"rs17238484\", \"rs429358_swap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Per Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prep data frame for per protocol subset\n",
    "pp_snp_df <- left_join(per_protocol_df, sid_targets)\n",
    "\n",
    "dim(pp_snp_df)\n",
    "# head(pp_snp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate allele frequencies overall\n",
    "allele_frequency(pp_snp_df, \"rs17238484\", \"rs429358_swap\")\n",
    "\n",
    "# Calculate allele frequencies by NOD status (1 = NOD, 0 = no NOD)\n",
    "allele_frequency(pp_snp_df %>% filter(status == 1), \"rs17238484\", \"rs429358_swap\")\n",
    "allele_frequency(pp_snp_df %>% filter(status == 0), \"rs17238484\", \"rs429358_swap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate HRs for each SNP in each treatment group\n",
    "pp_int_snps <- candidate_results(pp_snp_df, \"rs17238484\", \"rs429358_swap\")\n",
    "pp_int_snps\n",
    "\n",
    "# Calculate the p-interaction with statins for each SNP\n",
    "int_test(pp_snp_df, pp_int_snps, \"rs17238484\", \"rs429358_swap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Self-identified White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prep data frame for self-identified white subset\n",
    "white_snp_df <- left_join(white_df, sid_targets)\n",
    "\n",
    "dim(white_snp_df)\n",
    "# head(white_snp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate allele frequencies overall\n",
    "allele_frequency(white_snp_df, \"rs17238484\", \"rs429358_swap\")\n",
    "\n",
    "# Calculate allele frequencies by NOD status (1 = NOD, 0 = no NOD)\n",
    "allele_frequency(white_snp_df %>% filter(status == 1), \"rs17238484\", \"rs429358_swap\")\n",
    "allele_frequency(white_snp_df %>% filter(status == 0), \"rs17238484\", \"rs429358_swap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate HRs for each SNP in each treatment group\n",
    "white_int_snps <- candidate_results(white_snp_df, \"rs17238484\", \"rs429358_swap\")\n",
    "white_int_snps\n",
    "\n",
    "# Calculate the p-interaction with statins for each SNP\n",
    "int_test(white_snp_df, white_int_snps, \"rs17238484\", \"rs429358_swap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini PS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this step is to determine the association of all the candidate variants with SID at once. Since the individual effects of the candidate variants are so small, despite our fairly large sample size, we do not have enough power to detect these associations, which likely exist since all candidate variant interactions followed the expected statin on-target direction of effect. To remedy this, we want to add all the effects together into a polygenic score (PS) and find the association with SID, thus providing stronger evidence that on-target variants are associated with an increased risk of SID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Clean up the candidate variant data frame for mini PS\n",
    "mini_ps_snps <- sid_targets %>% \n",
    "                    select(-c(rs7412,\n",
    "                              rs10455872,\n",
    "                              rs429358)) %>% rename(rs7412 = rs7412_swap,\n",
    "                                               rs10455872 = rs10455872_swap,\n",
    "                                               rs429358 = rs429358_swap) %>% # Prepare the correct version of rs7412\n",
    "                    right_join(itt_df) # Get all covariate data\n",
    "\n",
    "dim(mini_ps_snps)\n",
    "head(mini_ps_snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generating a random 50/50 split in the intention-to-treat cohort\n",
    "# First 50% will be used to generate weights\n",
    "# Other 50% will be used to model association between PS and SID\n",
    "\n",
    "# Create df with statin users only\n",
    "mini_ps_statin <- mini_ps_snps %>% filter(group == 'user')\n",
    "\n",
    "# 50% of the sample size\n",
    "sample_size <- floor(0.50 * nrow(mini_ps_statin))\n",
    "\n",
    "# Set seed to make partition reproducible\n",
    "set.seed(42)\n",
    "\n",
    "# Generate sample indicies\n",
    "itrain <- sample(seq_len(nrow(mini_ps_statin)), size = sample_size)\n",
    "\n",
    "# Select person IDs for sampled statin users\n",
    "mini_ps_snps_train_ids <- mini_ps_statin[itrain, ] %>% select(person_id)\n",
    "mini_ps_snps_test_ids <- mini_ps_statin[-itrain, ] %>% select(person_id)\n",
    "\n",
    "# Filter for match groups to maintain matching structures\n",
    "mini_ps_snps_train <- mini_ps_snps %>% filter(match_group %in% mini_ps_snps_train_ids$person_id)\n",
    "mini_ps_snps_test <- mini_ps_snps %>% filter(match_group %in% mini_ps_snps_test_ids$person_id)\n",
    "\n",
    "# Check\n",
    "dim(mini_ps_snps_train) \n",
    "# head(mini_ps_snps_train)\n",
    "\n",
    "dim(mini_ps_snps_test)\n",
    "# head(mini_ps_snps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate PS weights\n",
    "\n",
    "# Set start and end rs IDs for indexing\n",
    "istart <- which(names(mini_ps_snps_train) == \"rs17238484\")\n",
    "iend <- which(names(mini_ps_snps_train) == \"rs429358\")\n",
    "\n",
    "# Initialize PS data frame\n",
    "ps_snp_df <- data.frame(\n",
    "    \n",
    "                group = character(),\n",
    "                snp = character(),\n",
    "                HR = numeric(),\n",
    "                lower_ci_HR = numeric(),\n",
    "                upper_ci_HR = numeric(),\n",
    "                HR_SE = numeric(),\n",
    "                HR_p = numeric()      \n",
    "            )\n",
    "\n",
    "# Run helper function to generate weights in non-users and statin users on all candidate variants\n",
    "for (snp in colnames(mini_ps_snps_train[, istart:iend])) {\n",
    "        ps_snp_df <- rbind(ps_snp_df, var_association(mini_ps_snps_train, snp))\n",
    "    }\n",
    "\n",
    "# View stratified HRs\n",
    "ps_snp_df\n",
    "\n",
    "# Calculate HR ratios (estimated interaction effect)\n",
    "ps_snp_df <- ps_snp_df %>% \n",
    "                select(group, variable, HR) %>%\n",
    "                spread(key = group, value = HR) %>%\n",
    "                mutate(HR_ratio = user / `non-user`)# %>%\n",
    "                # select(snp, HR_ratio)\n",
    "\n",
    "ps_snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate PS\n",
    "\n",
    "# Reshape dosages data frame from wide to long format\n",
    "mini_ps_snps_test_long <- mini_ps_snps_test %>% \n",
    "    select(FID, IID, group, rs17238484, rs12916, rs10455872, rs4149056, rs429358, rs7412) %>%\n",
    "    pivot_longer(cols = starts_with(\"rs\"), names_to = \"variable\", values_to = \"dosage\")\n",
    "\n",
    "# Merge effect sizes with dosages based on group and SNP\n",
    "merged_data <- merge(mini_ps_snps_test_long, ps_snp_df, by = c(\"variable\"))\n",
    "\n",
    "# Calculate the PS for each individual\n",
    "ps_scores <- merged_data %>%\n",
    "  group_by(IID) %>%\n",
    "  summarize(PS = sum(dosage * HR_ratio)) %>%\n",
    "  mutate(PS_norm = as.numeric(scale(PS))) # Normalize PS for more interpretible continuous associations\n",
    "\n",
    "# Print PS scores\n",
    "dim(ps_scores)\n",
    "# head(ps_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Join PS with covariate data and split into quintiles\n",
    "mini_ps_snps_df <- full_join(mini_ps_snps_test, ps_scores) %>% \n",
    "                        mutate(quintile = ntile(PS, 5),\n",
    "                               quintile = paste0(\"Q\", quintile),\n",
    "                               quintile_norm = ntile(PS_norm, 5),\n",
    "                               quintile_norm = paste0(\"Q\", quintile_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Summarize untransformed PS\n",
    "\n",
    "# Summarize PS by treatment group\n",
    "mini_ps_snps_df %>% group_by(group) %>%\n",
    "            summarize(percent_t2d = round(sum(t2d_status == \"Event\")/n(), digits = 3)*100,\n",
    "                      min = min(PS, na.rm = TRUE),\n",
    "                      median = median(PS, na.rm = TRUE),\n",
    "                      max = max(PS, na.rm = TRUE))\n",
    "\n",
    "# Define variables for Table 1\n",
    "myVars <- c(\"t2d_status\", \"PS\")\n",
    "catVars <- c(\"t2d_status\")\n",
    "\n",
    "# Create Table 1 to see differences in PS - by group\n",
    "tab_ps_scores <- CreateTableOne(vars = myVars, strata = \"group\", data = mini_ps_snps_df, factorVars = catVars, test = TRUE)\n",
    "as.data.frame(print(tab_ps_scores, noSpaces = TRUE, printToggle = FALSE))\n",
    "\n",
    "# Create Table 1 to see differences in PS - by T2D status\n",
    "tab_ps_scores <- CreateTableOne(vars = myVars, strata = \"t2d_status\", data = mini_ps_snps_df, factorVars = catVars, test = TRUE)\n",
    "as.data.frame(print(tab_ps_scores, noSpaces = TRUE, printToggle = FALSE))\n",
    "\n",
    "# Create grouped boxplots\n",
    "boxplot <- ggplot(mini_ps_snps_df, aes(x = group, y = PS, fill = group)) +\n",
    "                geom_boxplot() +\n",
    "                coord_flip() +\n",
    "                theme_void() +\n",
    "                scale_fill_manual(values = c(\"#C32882\", \"#178CCB\")) +\n",
    "                theme(legend.position = \"none\")\n",
    "\n",
    "# Create grouped density plots\n",
    "density_plot <- ggplot(mini_ps_snps_df, aes(x = PS, fill = group)) +\n",
    "                    geom_density(alpha = 0.5) +\n",
    "                    labs(x = \"PS Scores\", y = \"Density\") +\n",
    "                    scale_fill_manual(values = c(\"#C32882\", \"#178CCB\")) +\n",
    "                    theme_minimal()\n",
    "\n",
    "# Combine plots\n",
    "combined_plot <- plot_grid(boxplot, density_plot, ncol = 1, rel_heights = c(1, 8))\n",
    "print(combined_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Summarize normalized PS\n",
    "\n",
    "# Summarize PS by treatment group\n",
    "mini_ps_snps_df %>% group_by(group) %>%\n",
    "            summarize(percent_t2d = round(sum(t2d_status == \"Event\")/n(), digits = 3)*100,\n",
    "                      min = min(PS_norm, na.rm = TRUE),\n",
    "                      median = median(PS_norm, na.rm = TRUE),\n",
    "                      max = max(PS_norm, na.rm = TRUE))\n",
    "\n",
    "# Define variables for Table 1\n",
    "myVars <- c(\"t2d_status\", \"PS_norm\")\n",
    "catVars <- c(\"t2d_status\")\n",
    "\n",
    "# Create Table 1 to see differences in PS - by group\n",
    "tab_ps_scores <- CreateTableOne(vars = myVars, strata = \"group\", data = mini_ps_snps_df, factorVars = catVars, test = TRUE)\n",
    "as.data.frame(print(tab_ps_scores, noSpaces = TRUE, printToggle = FALSE))\n",
    "\n",
    "# Create Table 1 to see differences in PS - by T2D status\n",
    "tab_ps_scores <- CreateTableOne(vars = myVars, strata = \"t2d_status\", data = mini_ps_snps_df, factorVars = catVars, test = TRUE)\n",
    "as.data.frame(print(tab_ps_scores, noSpaces = TRUE, printToggle = FALSE))\n",
    "\n",
    "# Create grouped boxplots\n",
    "boxplot <- ggplot(mini_ps_snps_df, aes(x = group, y = PS_norm, fill = group)) +\n",
    "                geom_boxplot() +\n",
    "                coord_flip() +\n",
    "                theme_void() +\n",
    "                scale_fill_manual(values = c(\"#C32882\", \"#178CCB\")) +\n",
    "                theme(legend.position = \"none\")\n",
    "\n",
    "# Create grouped density plots\n",
    "density_plot <- ggplot(mini_ps_snps_df, aes(x = PS_norm, fill = group)) +\n",
    "                    geom_density(alpha = 0.5) +\n",
    "                    labs(x = \"Normalized PS Scores\", y = \"Density\") +\n",
    "                    scale_fill_manual(values = c(\"#C32882\", \"#178CCB\")) +\n",
    "                    theme_minimal()\n",
    "\n",
    "# Combine plots\n",
    "combined_plot <- plot_grid(boxplot, density_plot, ncol = 1, rel_heights = c(1, 8))\n",
    "print(combined_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check mini PS data frame\n",
    "dim(mini_ps_snps_df)\n",
    "# head(mini_ps_snps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Summarize mini PS by quintiles - untransformed\n",
    "mini_ps_snps_df %>% group_by(quintile) %>% summarize(count = n(),\n",
    "                                                      non_users = sum(group == \"non-user\"),\n",
    "                                                      users = sum(group == \"user\"),\n",
    "                                                      percent_t2d = round(sum(t2d_status == \"Event\")/n(), digits = 3)*100,\n",
    "                                                      min = min(PS),\n",
    "                                                      median = median(PS),\n",
    "                                                      mean = mean(PS),\n",
    "                                                      max = max(PS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Summarize mini PS by quintiles - normalized\n",
    "mini_ps_snps_df %>% group_by(quintile_norm) %>% summarize(count = n(),\n",
    "                                                      non_users = sum(group == \"non-user\"),\n",
    "                                                      users = sum(group == \"user\"),\n",
    "                                                      percent_t2d = round(sum(t2d_status == \"Event\")/n(), digits = 3)*100,\n",
    "                                                      min = min(PS_norm),\n",
    "                                                      median = median(PS_norm),\n",
    "                                                      mean = mean(PS_norm),\n",
    "                                                      max = max(PS_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PS Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Untransformed PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Association of NOD and a 1-point increase in PS, stratified by treatment group\n",
    "ps_overall <- var_association(mini_ps_snps_df, \"PS\")\n",
    "ps_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Heterogeneity test for interaction between PS and NOD\n",
    "int_test(mini_ps_snps_df, ps_overall, \"PS\", \"PS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate HRs for each SNP in each treatment group\n",
    "ps_quintiles <- psq_association(mini_ps_snps_df, 'quintile', \n",
    "                                  c(\"quintileQ2\", \"quintileQ3\", \"quintileQ4\", \"quintileQ5\"))\n",
    "\n",
    "# Calculate proportion of NOD cases for each treatment group and quintile\n",
    "nod_prop <- mini_ps_snps_df %>% group_by(group, quintile) %>% \n",
    "                summarize(group = group, \n",
    "                          quintile = paste0('quintile', quintile), \n",
    "                          prop_nod = sum(t2d_status == \"Event\")/n()) %>%\n",
    "                distinct(.keep_all = TRUE)\n",
    "\n",
    "# Join data frames\n",
    "ps_quintiles <- left_join(ps_quintiles, nod_prop)\n",
    "ps_quintiles\n",
    "\n",
    "# Initialize P of interaction data frame\n",
    "int_p_df <- data.frame(q = character(), p_int_calc = numeric())\n",
    "\n",
    "# Loop through each quintile and calculate P of interaction for each\n",
    "for (q in c(\"quintileQ2\", \"quintileQ3\", \"quintileQ4\", \"quintileQ5\")) {\n",
    "        \n",
    "        # Calculate P of interaction\n",
    "        calc_p <- p_int_calculator(ps_quintiles[ps_quintiles$quintile == q & ps_quintiles$group == \"non-user\", \"beta\"], \n",
    "                                  ps_quintiles[ps_quintiles$quintile == q & ps_quintiles$group == \"non-user\", \"HR_SE\"],\n",
    "                                  ps_quintiles[ps_quintiles$quintile == q & ps_quintiles$group == \"user\", \"beta\"], \n",
    "                                  ps_quintiles[ps_quintiles$quintile == q & ps_quintiles$group == \"user\", \"HR_SE\"])\n",
    "        \n",
    "        # Assign necessary variables\n",
    "        q_name <- q\n",
    "        grp_p_calc <- calc_p\n",
    "        \n",
    "        # Bind results together\n",
    "        int_p_df <- rbind(int_p_df, data.frame(\n",
    "                            quintile = q_name,\n",
    "                            p_int_calc = grp_p_calc))\n",
    "    }\n",
    "    \n",
    "int_p_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Association of NOD and a 1-point increase in PS, stratified by treatment group\n",
    "ps_overall <- var_association(mini_ps_snps_df, \"PS_norm\")\n",
    "ps_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Heterogeneity test for interaction between PS and NOD\n",
    "int_test(mini_ps_snps_df, ps_overall, \"PS_norm\", \"PS_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate HRs for each SNP in each treatment group\n",
    "ps_quintiles <- psq_association(mini_ps_snps_df, 'quintile_norm', \n",
    "                                  c(\"quintile_normQ2\", \"quintile_normQ3\", \"quintile_normQ4\", \"quintile_normQ5\"))\n",
    "\n",
    "# Calculate proportion of NOD cases for each treatment group and quintile\n",
    "nod_prop <- mini_ps_snps_df %>% group_by(group, quintile_norm) %>% \n",
    "                summarize(group = group, \n",
    "                          quintile = paste0('quintile_norm', quintile_norm), \n",
    "                          prop_nod = sum(t2d_status == \"Event\")/n()) %>%\n",
    "                distinct(.keep_all = TRUE)\n",
    "\n",
    "# Join data frames\n",
    "ps_quintiles <- left_join(ps_quintiles, nod_prop)\n",
    "ps_quintiles\n",
    "\n",
    "# Initialize P of interaction data frame\n",
    "int_p_df <- data.frame(q = character(), p_int_calc = numeric())\n",
    "\n",
    "# Loop through each quintile and calculate P of interaction for each\n",
    "for (q in c(\"quintile_normQ2\", \"quintile_normQ3\", \"quintile_normQ4\", \"quintile_normQ5\")) {\n",
    "        \n",
    "        # Calculate P of interaction\n",
    "        calc_p <- p_int_calculator(ps_quintiles[ps_quintiles$quintile == q & ps_quintiles$group == \"non-user\", \"beta\"], \n",
    "                                  ps_quintiles[ps_quintiles$quintile == q & ps_quintiles$group == \"non-user\", \"HR_SE\"],\n",
    "                                  ps_quintiles[ps_quintiles$quintile == q & ps_quintiles$group == \"user\", \"beta\"], \n",
    "                                  ps_quintiles[ps_quintiles$quintile == q & ps_quintiles$group == \"user\", \"HR_SE\"])\n",
    "        \n",
    "        # Assign necessary variables\n",
    "        q_name <- q\n",
    "        grp_p_calc <- calc_p\n",
    "        \n",
    "        # Bind results together\n",
    "        int_p_df <- rbind(int_p_df, data.frame(\n",
    "                            quintile = q_name,\n",
    "                            p_int_calc = grp_p_calc))\n",
    "    }\n",
    "    \n",
    "int_p_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Forest Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create a forest plot \n",
    "\n",
    "# Clean up quintile names before merging\n",
    "ps_fp <- ps_quintiles %>%\n",
    "  mutate(quintile = gsub(\"quintile_norm\", \"\", quintile))  # Remove \"quintile_norm\" prefix\n",
    "\n",
    "int_p_df <- int_p_df %>%\n",
    "  mutate(quintile = gsub(\"quintile_norm\", \"\", quintile))  # Remove \"quintile_norm\" prefix\n",
    "\n",
    "# Merge the two dataframes\n",
    "ps_fp <- ps_fp %>%\n",
    "  left_join(int_p_df, by = c(\"quintile\"))\n",
    "\n",
    "# Create labels for the plot\n",
    "ps_fp <- ps_fp %>%\n",
    "  mutate(\n",
    "    prop_nod_pct = prop_nod * 100, # Convert prop_nod to percentage\n",
    "    label = sprintf(\"%.2f (%.2f-%.2f)\", HR, lower_ci_HR, upper_ci_HR) # Create formatted string for display\n",
    "  )\n",
    "\n",
    "# Create the forest plot\n",
    "p <- ggplot(ps_fp, aes(y = quintile)) +\n",
    "  geom_vline(xintercept = 1, linetype = \"dashed\", color = \"gray50\") + # Add vertical line at HR = 1\n",
    "  geom_point(aes(x = HR, shape = group, color = group), position = position_dodge(width = 0.5)) + # Add points and confidence intervals\n",
    "  geom_errorbarh(aes(xmin = lower_ci_HR, xmax = upper_ci_HR, linetype = group, color = group), \n",
    "                 height = 0.2, position = position_dodge(width = 0.5)) +\n",
    "  scale_x_continuous(breaks = seq(0.5, 2, 0.25)) + # Customize appearance\n",
    "  scale_color_manual(values = c(\"blue\", \"red\")) +\n",
    "  scale_linetype_manual(values = c(\"dashed\", \"solid\")) +\n",
    "  theme_bw() +\n",
    "  labs(x = \"Hazard Ratio (95% CI)\", y = \"Quintile\") +\n",
    "  theme(legend.position = \"top\")\n",
    "\n",
    "# Create a table with the numerical results and round all numeric columns to 2 decimal places\n",
    "results_table <- ps_fp %>%\n",
    "  select(quintile, group, HR, lower_ci_HR, upper_ci_HR, HR_p, prop_nod_pct, p_int_calc) %>%\n",
    "  arrange(quintile, group) %>%\n",
    "  mutate(across(where(is.numeric), ~round(., 3)))\n",
    "\n",
    "# Print both plot and table\n",
    "p\n",
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to determine HR in each population for numeric variables (dosage or PS), split by treatment group\n",
    "var_association_ldl <- function(df, ps, var) {\n",
    "    \n",
    "    # Initialize the outputed data frame\n",
    "    var_df <- data.frame(\n",
    "                group = character(),\n",
    "                variable = character(),\n",
    "                beta = numeric(),\n",
    "                HR = numeric(),\n",
    "                lower_ci_HR = numeric(),\n",
    "                upper_ci_HR = numeric(),\n",
    "                HR_SE = numeric(),\n",
    "                HR_p = numeric()      \n",
    "            )\n",
    "    \n",
    "    # Split input data frame by treatment group\n",
    "    grp_split <- split(\n",
    "        df,\n",
    "        df[,\"group\"],\n",
    "        drop = FALSE\n",
    "        )\n",
    "    \n",
    "    # Loop through split treatment group data frames\n",
    "    for (i in names(grp_split)) {\n",
    "        \n",
    "        # If running this analysis in self-identified white subset, exclude population covariate,\n",
    "        # else, include population covariate\n",
    "        if(all(df$population == \"White\")) {\n",
    "            \n",
    "            int_formula <- as.formula(paste0(ps \" ~ \", var, \" + index_age + sex_at_birth +\n",
    "                                    low_hdl + high_tg + high_bmi + smoking_status + htn_status + gd_status +\n",
    "                                    PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + \n",
    "                                    PC13 + PC14 + PC15 + PC16\"))\n",
    "            \n",
    "        } else {\n",
    "            \n",
    "            int_formula <- as.formula(paste0(ps \" ~ \", var, \" + index_age + population + sex_at_birth +\n",
    "                                    low_hdl + high_tg + high_bmi + smoking_status + htn_status + gd_status +\n",
    "                                    PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + \n",
    "                                    PC13 + PC14 + PC15 + PC16\"))\n",
    "            \n",
    "        }\n",
    "        \n",
    "        # Run model\n",
    "        int_m <- coxph(int_formula, data = grp_split[[i]])\n",
    "        \n",
    "        # Extract necessary outcomes from model output\n",
    "        grp <- i\n",
    "        var_name <- var\n",
    "        grp_beta <- coef(summary(int_m))[paste0(var), \"coef\"]\n",
    "        grp_HR <- coef(summary(int_m))[paste0(var), \"exp(coef)\"]\n",
    "        grp_lower <- exp(confint(int_m))[paste0(var), \"2.5 %\"]\n",
    "        grp_upper <- exp(confint(int_m))[paste0(var), \"97.5 %\"]\n",
    "        grp_SE <- coef(summary(int_m))[paste0(var), \"se(coef)\"]\n",
    "        grp_p <- coef(summary(int_m))[paste0(var), \"Pr(>|z|)\"]\n",
    "        \n",
    "        # Bind results to initialized data frame\n",
    "        var_df <- rbind(var_df, data.frame(\n",
    "                group = grp,\n",
    "                variable = var_name,\n",
    "                beta = grp_beta,\n",
    "                HR = grp_HR,\n",
    "                lower_ci_HR = grp_lower,\n",
    "                upper_ci_HR = grp_upper,\n",
    "                HR_SE = grp_SE,\n",
    "                HR_p = grp_p))\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return(var_df)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Association of NOD and a 1-point increase in PS, stratified by treatment group\n",
    "mini_ps_snps_df_ldl <- left_join(mini_ps_snps_df, ldl_df)\n",
    "\n",
    "dim(mini_ps_snps_df_ldl)\n",
    "head(mini_ps_snps_df_ldl)\n",
    "\n",
    "ps_overall <- var_association_ldl(mini_ps_snps_df_ldl, \"PS_norm\", \"max_decrease_ldl\")\n",
    "ps_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions - GWAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: Create functions to streamline analysis of genome-wide association studies (GWAS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to create a data frame with interaction results for GWAS\n",
    "interaction_test <- function(statin_res, nu_res) {\n",
    "    \n",
    "    # Combine \n",
    "    int_results <- full_join(statin_res, nu_res, by = join_by(CHROM, GENPOS, ID, ALLELE0, ALLELE1)) %>%\n",
    "                            group_by(ID) %>%\n",
    "                            mutate(p_int = p_int_calculator(BETA.x, SE.x, BETA.y, SE.y)) %>%\n",
    "                            arrange(p_int)\n",
    "    \n",
    "    return(int_results)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWAS - Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this section is to find out if any variants have a genome-wide association with SID. This is done by first running GWAS in statin users and non-users separately to find the effect size of each variant in their respective treatment groups. The next steps is to use the Cochran's Q test to find the heterogeneity between each treatment group for each variant. If the P value from this test is less than a Boneferroni corrected 5 x 10<sup>-8</sup>, the interaction is considered genome-wide significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intention-to-treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Manhattan plot + qq plot for statin users\n",
    "options(repr.plot.width=15, repr.plot.height=8)\n",
    "manhattan(array_statin_itt_MAF1, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"LOG10P\", annotatePval = 0.01)\n",
    "qq(array_statin_itt_MAF1$LOG10P)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_statin_itt_MAF1 %>% arrange(LOG10P), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Manhattan plot + qq plot for non-users\n",
    "manhattan(array_nu_itt_MAF1, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"LOG10P\", annotatePval = 0.01)\n",
    "qq(array_nu_itt_MAF1$LOG10P)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_nu_itt_MAF1 %>% arrange(LOG10P), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate interaction p-values\n",
    "array_itt_MAF1_int <- interaction_test(array_statin_itt_MAF1, array_nu_itt_MAF1)\n",
    "\n",
    "dim(array_itt_MAF1_int)\n",
    "head(array_itt_MAF1_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate interaction Manhattan plot + qq plot\n",
    "manhattan(array_itt_MAF1_int, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"p_int\", annotatePval = 0.01)\n",
    "qq(array_itt_MAF1_int$p_int)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_itt_MAF1_int %>% arrange(p_int), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ≥30% Decrease in LDL-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Manhattan plot + qq plot for statin users\n",
    "manhattan(array_statin_ldl30_MAF25, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"LOG10P\", annotatePval = 0.01)\n",
    "qq(array_statin_ldl30_MAF25$LOG10P)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_statin_ldl30_MAF25 %>% arrange(LOG10P), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Manhattan plot + qq plot for non-users\n",
    "manhattan(array_nu_ldl30_MAF25, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"LOG10P\", annotatePval = 0.01)\n",
    "qq(array_nu_ldl30_MAF25$LOG10P)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_nu_ldl30_MAF25 %>% arrange(LOG10P), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate interaction p-values\n",
    "array_ldl30_MAF25_int <- interaction_test(array_statin_ldl30_MAF25, array_nu_ldl30_MAF25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate interaction Manhattan plot + qq plot\n",
    "manhattan(array_ldl30_MAF25_int, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"p_int\", annotatePval = 0.01)\n",
    "qq(array_ldl30_MAF25_int$p_int)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_ldl30_MAF25_int %>% arrange(p_int), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Manhattan plot + qq plot for statin users\n",
    "manhattan(array_statin_pp_MAF20, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"LOG10P\", annotatePval = 0.01)\n",
    "qq(array_statin_pp_MAF20$LOG10P)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_statin_pp_MAF20 %>% arrange(LOG10P), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Manhattan plot + qq plot for non-users\n",
    "manhattan(array_nu_pp_MAF20, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"LOG10P\", annotatePval = 0.01)\n",
    "qq(array_nu_pp_MAF20$LOG10P)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_nu_pp_MAF20 %>% arrange(LOG10P), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate interaction p-values\n",
    "array_pp_MAF20_int <- interaction_test(array_statin_pp_MAF20, array_nu_pp_MAF20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate interaction Manhattan plot + qq plot\n",
    "manhattan(array_pp_MAF20_int, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"p_int\", annotatePval = 0.01)\n",
    "qq(array_pp_MAF20_int$p_int)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_pp_MAF20_int %>% arrange(p_int), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Manhattan plot + qq plot for statin users\n",
    "manhattan(array_statin_white_MAF1, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"LOG10P\", annotatePval = 0.01)\n",
    "qq(array_statin_white_MAF1$LOG10P)\n",
    "\n",
    "# Generate tqaE34Rop 10 SNPs\n",
    "head(array_statin_white_MAF1 %>% arrange(LOG10P), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Manhattan plot + qq plot for non-users\n",
    "manhattan(array_nu_white_MAF1, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"LOG10P\", annotatePval = 0.01)\n",
    "qq(array_nu_white_MAF1$LOG10P)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_nu_white_MAF1 %>% arrange(LOG10P), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate interaction p-values\n",
    "array_white_MAF1_int <- interaction_test(array_statin_white_MAF1, array_nu_white_MAF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate interaction Manhattan plot + qq plot\n",
    "manhattan(array_white_MAF1_int, chr=\"CHROM\", bp=\"GENPOS\", snp=\"ID\", p=\"p_int\", annotatePval = 0.01)\n",
    "qq(array_white_MAF1_int$p_int)\n",
    "\n",
    "# Generate top 10 SNPs\n",
    "head(array_white_MAF1_int %>% arrange(p_int), 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
