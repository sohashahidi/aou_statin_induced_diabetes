{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SID Genetics Study Step 5: Developing Genotype\n",
    "\n",
    "## Objective\n",
    "The purpose of this notebook is to pull genetic data (primarily in the form of dosages), for the various genetic analyses in the statin-induced diabetes (SID) study. This notebook also contains code for time-to-event genome-wide association studies (GWAS) using Regenie 4.1. GWAS are run twice for each analysis: once on statin users and once on non-users. This is so the effect sizes in each treatment group are known, and heterogeneity tests (Cochran's Q) will be run in the next notebook to determine heterogeneity.\n",
    "\n",
    "Unlike previous notebooks in this study, this notebook is primarily run using Python and bash scripting.\n",
    "\n",
    "Run the \"1. dsub set up and ReadMe.ipynb\" notebook from the \"How to use dsub in the Researcher Workbench\" featured workspace on AoU before running this notebook to submit dsub jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get workspace bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "my_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get username and save it to the environment\n",
    "USER_NAME = os.getenv('OWNER_EMAIL').split('@')[0].replace('.','-')\n",
    "\n",
    "# Save this Python variable as an environment variable so that its easier to use within %%bash cells.\n",
    "%env USER_NAME={USER_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the locations of genomic datasets\n",
    "genomic_location = os.getenv(\"CDR_STORAGE_PATH\")\n",
    "%env genomic_location = {genomic_location}\n",
    "\n",
    "# Get the location of short read snps\n",
    "wgs_plink_path = f'{genomic_location}/wgs/short_read/snpindel'\n",
    "%env wgs_plink_path = {wgs_plink_path}\n",
    "\n",
    "acaf_plink_path = f'{wgs_plink_path}/acaf_threshold'\n",
    "%env acaf_plink_path = {acaf_plink_path}\n",
    "\n",
    "%env my_bucket = {my_bucket}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Gene Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this section is to pull statin on-target candidate variants from AoU's ACAF Threshold callset using PLINK 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to pull candidate variants from the ACAF Threshold callset\n",
    "%%writefile candidateSNP_SID.sh\n",
    "set -o errexit\n",
    "set -o nounset\n",
    "\n",
    "if [ -n \"${SNP_LIST}\" ]; then\n",
    "    plink2 \\\n",
    "      --bed \"${input_file1}\" \\\n",
    "      --bim \"${input_file2}\" \\\n",
    "      --fam \"${input_file3}\" \\\n",
    "      --snps \"${SNP_LIST}\" \\\n",
    "      --keep \"${ids}\" \\\n",
    "      --export A \\\n",
    "      --out \"${out_path}/sid_targets_chr${CHROMO}\"\n",
    "else\n",
    "    echo \"No SNPs found for chromosome ${CHROMO}, skipping plink2 command.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy script to bucket\n",
    "%%bash\n",
    "gsutil cp candidateSNP_SID.sh \"${my_bucket}/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job using dsub\n",
    "%%bash --out candidate_study_sid\n",
    "source ~/aou_dsub.bash\n",
    "\n",
    "# Define script path and type data\n",
    "BASH_SCRIPT=\"${my_bucket}/data/candidateSNP_SID.sh\"\n",
    "\n",
    "chromosomes=(5 6 12 19)\n",
    "snps=(\"chr5:75352671:G:T\" \"chr5:75360714:T:C\" \"chr6:160589086:A:G\" \"chr12:21178615:T:C\" \"chr19:44908822:C:T\" \"chr19:44908684:T:C\")\n",
    "\n",
    "# Loop through each chromosome number\n",
    "for chromo in \"${chromosomes[@]}\"; do\n",
    "  # Filter SNPs for the current chromosome\n",
    "  filtered_snps=()\n",
    "  for snp in \"${snps[@]}\"; do\n",
    "    if [[ \"$snp\" == chr${chromo}:* ]]; then\n",
    "      filtered_snps+=(\"$snp\")\n",
    "    fi\n",
    "  done\n",
    "\n",
    "  # Convert filtered SNPs array to a comma-separated string\n",
    "  snp_list=$(IFS=,; echo \"${filtered_snps[*]}\")\n",
    "\n",
    "  # Run dsub command\n",
    "  aou_dsub \\\n",
    "    --image us.gcr.io/broad-dsp-gcr-public/terra-jupyter-aou:2.1.19 \\\n",
    "    --disk-size 1096 \\\n",
    "    --boot-disk-size 200 \\\n",
    "    --logging \"${my_bucket}/data/logging\" \\\n",
    "    --input input_file1=\"${wgs_plink_path}/acaf_threshold/plink_bed/chr${chromo}.bed\" \\\n",
    "    --input input_file2=\"${wgs_plink_path}/acaf_threshold/plink_bed/chr${chromo}.bim\" \\\n",
    "    --input input_file3=\"${wgs_plink_path}/acaf_threshold/plink_bed/chr${chromo}.fam\" \\\n",
    "    --input ids=\"${my_bucket}/sid_pheno_files/genomic/itt_ids_v2.txt\" \\\n",
    "    --env SNP_LIST=\"${snp_list}\" \\\n",
    "    --env CHROMO=\"${chromo}\" \\\n",
    "    --output-recursive out_path=\"${my_bucket}/sid_geno_files/candidate/\" \\\n",
    "    --script \"${BASH_SCRIPT}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View job status summary\n",
    "%%bash\n",
    "\n",
    "dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --location us-central1 \\\n",
    "    --names \"candidatesnp-sid\" \\\n",
    "    --users \"${USER_NAME}\" \\\n",
    "    --status '*' | head -n 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View detailed job summaries\n",
    "%%bash\n",
    "\n",
    "dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --location us-central1 \\\n",
    "    --names \"candidatesnp-sid\" \\\n",
    "    --users \"${USER_NAME}\" \\\n",
    "    --status '*' \\\n",
    "    --full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microarray Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this notebook is to run quality control (QC) with PLINK 2.0 and a genome-wide association study with Regenie 4.1 using AoU's microarray dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to run QC on microarray data for our cohort\n",
    "# Minor allele frequency (MAF) can be changed, since MAFs that are too low may prevent GWAS from converging\n",
    "%%writefile ~/filter_snps_allchr.sh\n",
    "\n",
    "set -o pipefail \n",
    "set -o errexit\n",
    "\n",
    "plink2 \\\n",
    "--bed \"${input_bed}\" \\\n",
    "--bim \"${input_bim}\" \\\n",
    "--fam \"${input_fam}\" \\\n",
    "--keep \"${ids}\" \\\n",
    "--maf \"${MAF}\" --mac 100 --geno 0.1 \\\n",
    "--mind 0.1 \\\n",
    "--write-snplist --write-samples --no-id-header \\\n",
    "--out \"${OUTPUT_PATH}/qc_pass_maf${MAF_name}_${group}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy script to bucket\n",
    "!gsutil cp /home/jupyter/filter_snps_allchr.sh {my_bucket}/data/dsub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out test_ID\n",
    "\n",
    "source ~/aou_dsub.bash # This file was created via notebook 01_dsub_setup.ipynb.\n",
    "\n",
    "BASH_SCRIPT=\"${my_bucket}/data/dsub/filter_snps_allchr.sh\"\n",
    "\n",
    "# Variable to hold which subset must be filtered\n",
    "group_name=ldl30\n",
    "\n",
    "aou_dsub \\\n",
    "      --image us.gcr.io/broad-dsp-gcr-public/terra-jupyter-aou:2.1.19 \\\n",
    "      --disk-size 1024 \\\n",
    "      --boot-disk-size 1000 \\\n",
    "      --logging \"${my_bucket}/data/logging\" \\\n",
    "      --input input_bed=\"${genomic_location}/microarray/plink/arrays.bed\" \\\n",
    "      --input input_bim=\"${genomic_location}/microarray/plink/arrays.bim\" \\\n",
    "      --input input_fam=\"${genomic_location}/microarray/plink/arrays.fam\" \\\n",
    "      --input ids=\"${my_bucket}/sid_pheno_files/genomic/${group_name}_statin_ids_v2.txt\" \\\n",
    "      --env MAF=0.25 \\\n",
    "      --env MAF_name=25 \\\n",
    "      --env group=${group_name} \\\n",
    "      --output-recursive OUTPUT_PATH=\"${my_bucket}/sid_geno_files/snps_pass/array/${group_name}/\" \\\n",
    "      --script \"${BASH_SCRIPT}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View job status summary\n",
    "%%bash\n",
    "dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project ${GOOGLE_PROJECT} \\\n",
    "    --location us-central1 \\\n",
    "    --name \"filter-snps-allchr\" \\\n",
    "    --users ${USER_NAME} \\\n",
    "    --status '*' | head -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View detailed job summaries\n",
    "%%bash\n",
    "dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project ${GOOGLE_PROJECT} \\\n",
    "    --location us-central1 \\\n",
    "    --name \"filter-snps-allchr\" \\\n",
    "    --users ${USER_NAME} \\\n",
    "    --status '*' \\\n",
    "    --full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that QC files were created\n",
    "%%bash\n",
    "gsutil -u ${GOOGLE_PROJECT} ls \"${my_bucket}/sid_geno_files/snps_pass/array/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to run time-to-event GWAS with Regenie 4.1\n",
    "%%writefile ~/sid_gwas_regenie_array.sh\n",
    "\n",
    "set -o pipefail \n",
    "set -o errexit\n",
    "\n",
    "regenie \\\n",
    "    --step 1 \\\n",
    "    --bed \"${bed_file}/arrays\" \\\n",
    "    --extract \"${keep_snps}\" \\\n",
    "    --keep \"${ids}\" \\\n",
    "    --phenoFile \"${pheno_file}\" \\\n",
    "    --phenoColList time \\\n",
    "    --eventColList status \\\n",
    "    --covarFile \"${cov_file}\" \\\n",
    "    --covarColList low_hdl,high_tg,high_bmi,pd_status,smoking_status,htn_status,gd_status,index_age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15,PC16,male \\\n",
    "    --t2e \\\n",
    "    --bsize 1000 \\\n",
    "    --verbose \\\n",
    "    --force-step1 \\\n",
    "    --out \"${OUTPUT_PATH}/${prefix}\"_step1_array \\\n",
    "    --threads 16\n",
    "\n",
    "#regenie pt 2\n",
    "regenie \\\n",
    "    --step 2 \\\n",
    "    --bed \"${bed_file}/arrays\" \\\n",
    "    --extract \"${keep_snps}\" \\\n",
    "    --keep \"${ids}\" \\\n",
    "    --phenoFile \"${pheno_file}\" \\\n",
    "    --phenoColList time \\\n",
    "    --eventColList status \\\n",
    "    --covarFile \"${cov_file}\" \\\n",
    "    --covarColList low_hdl,high_tg,high_bmi,pd_status,smoking_status,htn_status,gd_status,index_age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15,PC16,male \\\n",
    "    --pred \"${OUTPUT_PATH}/${prefix}\"_step1_array_pred.list \\\n",
    "    --t2e \\\n",
    "    --firth --approx \\\n",
    "    --bsize 400 \\\n",
    "    --verbose \\\n",
    "    --threads 16 \\\n",
    "    --out \"${OUTPUT_PATH}/${prefix}\"_step2_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy script to personal bucket\n",
    "!gsutil cp /home/jupyter/sid_gwas_regenie_array.sh {my_bucket}/data/dsub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Submit job to dsub\n",
    "%%bash --out LINE_COUNT_JOB_ID\n",
    "\n",
    "# Get a shorter username to leave more characters for the job name.\n",
    "DSUB_USER_NAME=\"$(echo \"${OWNER_EMAIL}\" | cut -d@ -f1)\"\n",
    "\n",
    "# For AoU RWB projects network name is \"network\".\n",
    "AOU_NETWORK=network\n",
    "AOU_SUBNETWORK=subnetwork\n",
    "\n",
    "MACHINE_TYPE=\"n2-standard-4\"\n",
    "\n",
    "# Change for your bucket, path in output of cell directly above:\n",
    "BASH_SCRIPT=\"${my_bucket}/data/dsub/sid_gwas_regenie_array.sh\"\n",
    "\n",
    "# Choose which MAFs to run thw gwas one\n",
    "mafs=(25)\n",
    "\n",
    "for MAF_name in \"${mafs[@]}\"; do\n",
    "\n",
    "# Choose which subset and treatment group to run GWAS on\n",
    "subset_name=ldl30\n",
    "group_name=nu\n",
    "\n",
    "dsub \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --user-project \"${GOOGLE_PROJECT}\" \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --image shinshinbooboo210/regenie_gsutil:v4.1 \\\n",
    "    --network \"${AOU_NETWORK}\" \\\n",
    "    --subnetwork \"${AOU_SUBNETWORK}\" \\\n",
    "    --service-account \"$(gcloud config get-value account)\" \\\n",
    "    --user \"${DSUB_USER_NAME}\" \\\n",
    "    --regions us-central1 \\\n",
    "    --logging \"${WORKSPACE_BUCKET}/dsub/logs/{job-name}/{user-id}/$(date +'%Y%m%d/%H%M%S')/{job-id}-{task-id}-{task-attempt}.log\" \\\n",
    "    \"$@\" \\\n",
    "    --preemptible \\\n",
    "    --disk-size 3000 \\\n",
    "    --boot-disk-size 300 \\\n",
    "    --machine-type ${MACHINE_TYPE} \\\n",
    "    --name \"${JOB_NAME}\" \\\n",
    "    --script \"${BASH_SCRIPT}\" \\\n",
    "    --env GOOGLE_PROJECT=${GOOGLE_PROJECT} \\\n",
    "    --input-recursive bed_file=\"${genomic_location}/microarray/plink/\" \\\n",
    "    --input keep_snps=\"${my_bucket}/sid_geno_files/snps_pass/array/${subset_name}/qc_pass_maf${MAF_name}_${subset_name}.snplist\" \\\n",
    "    --input ids=\"${my_bucket}/sid_pheno_files/genomic/${subset_name}_ids_v2.txt\" \\\n",
    "    --input pheno_file=\"${my_bucket}/sid_pheno_files/genomic/${subset_name}_${group_name}_pheno_df.tsv\" \\\n",
    "    --input cov_file=\"${my_bucket}/sid_pheno_files/genomic/${subset_name}_${group_name}_covs_df.tsv\" \\\n",
    "    --env prefix=SID_GWAS_array_${group_name}_${subset_name}_MAF${MAF_name} \\\n",
    "    --output-recursive OUTPUT_PATH=\"${my_bucket}/sid_geno_files/arrays/${subset_name}/\"\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View job status summary\n",
    "%%bash\n",
    "dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project ${GOOGLE_PROJECT} \\\n",
    "    --location us-central1 \\\n",
    "    --names \"sid-gwas-regenie-array\" \\\n",
    "    --users ${USER_NAME} \\\n",
    "    --status '*' | head -n 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View detailed job summary\n",
    "%%bash\n",
    "dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project ${GOOGLE_PROJECT} \\\n",
    "    --location us-central1 \\\n",
    "    --names \"sid-gwas-regenie-array\" \\\n",
    "    --users ${USER_NAME} \\\n",
    "    --status '*' \\\n",
    "    --full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that files were created properly\n",
    "%%bash\n",
    "gsutil -u ${GOOGLE_PROJECT} ls \"${my_bucket}/sid_geno_files/arrays/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this notebook is to run quality control (QC) with PLINK 2.0 and a genome-wide association study with Regenie 4.1 using sequencing data from AoU's ACAF Threshold callset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to run QC on ACAF Threshold callset\n",
    "%%writefile ~/filter_snps.sh\n",
    "\n",
    "set -o pipefail \n",
    "set -o errexit\n",
    "\n",
    "plink2 \\\n",
    "    --bed \"${input_bed}\" \\\n",
    "    --bim \"${input_bim}\" \\\n",
    "    --fam \"${input_fam}\" \\\n",
    "    --keep \"${ids}\" \\\n",
    "    --mac 100 --geno 0.1 \\\n",
    "    --mind 0.1 \\\n",
    "    --write-snplist \\\n",
    "    --out \"${out_path}/snps_pass_chr${CHROMO}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy script to bucket\n",
    "!gsutil cp /home/jupyter/filter_snps.sh {my_bucket}/data/dsub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job to dsub\n",
    "%%bash --out test_ID\n",
    "\n",
    "source ~/aou_dsub.bash # This file was created via notebook 01_dsub_setup.ipynb.\n",
    "\n",
    "BASH_SCRIPT=\"${my_bucket}/data/dsub/filter_snps.sh\"\n",
    "\n",
    "LOWER=1\n",
    "UPPER=23\n",
    "for ((chromo=$LOWER;chromo<$UPPER;chromo+=1))\n",
    "do\n",
    "\n",
    "# Choose which subset to filter\n",
    "subset_name=itt\n",
    "\n",
    "    aou_dsub \\\n",
    "      --image us.gcr.io/broad-dsp-gcr-public/terra-jupyter-aou:2.1.19 \\\n",
    "      --disk-size 1024 \\\n",
    "      --boot-disk-size 1000 \\\n",
    "      --logging \"${my_bucket}/data/logging\" \\\n",
    "      --input input_bed=\"${acaf_plink_path}/plink_bed/chr${chromo}.bed\" \\\n",
    "      --input input_bim=\"${acaf_plink_path}/plink_bed/chr${chromo}.bim\" \\\n",
    "      --input input_fam=\"${acaf_plink_path}/plink_bed/chr${chromo}.fam\" \\\n",
    "      --input ids=\"${my_bucket}/sid_pheno_files/genomic/${subset_name}_statin_ids_v2.txt\" \\\n",
    "      --env CHROMO=${chromo} \\\n",
    "      --output-recursive out_path=\"${my_bucket}/sid_geno_files/snps_pass/sequence/${subset_name}/\" \\\n",
    "      --script \"${BASH_SCRIPT}\"  \n",
    "  \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View job status summary\n",
    "%%bash\n",
    "dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project ${GOOGLE_PROJECT} \\\n",
    "    --location us-central1 \\\n",
    "    --names \"filter-snps\" \\\n",
    "    --users ${USER_NAME} \\\n",
    "    --status '*'  | head -n 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View more detailed job summaries\n",
    "%%bash\n",
    "dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project ${GOOGLE_PROJECT} \\\n",
    "    --location us-central1 \\\n",
    "    --names \"filter-snps\" \\\n",
    "    --users ${USER_NAME} \\\n",
    "    --status '*' \\\n",
    "    --full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that files were created\n",
    "%%bash\n",
    "gsutil -u ${GOOGLE_PROJECT} ls \"${my_bucket}/data/plink_result/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to run time-to-event GWAS on ACAF Threshold data\n",
    "%%writefile ~/sid_gwas_regenie.sh\n",
    "\n",
    "set -o pipefail\n",
    "set -o errexit\n",
    "\n",
    "regenie \\\n",
    "    --step 1 \\\n",
    "    --bed \"${array_path}/arrays\" \\\n",
    "    --extract \"${keep_snps}\" \\\n",
    "    --keep \"${ids}\" \\\n",
    "    --phenoFile \"${pheno_file}\" \\\n",
    "    --phenoColList time \\\n",
    "    --eventColList status \\\n",
    "    --covarFile \"${cov_file}\" \\\n",
    "    --covarColList low_hdl,high_tg,high_bmi,pd_status,smoking_status,htn_status,gd_status,index_age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15,PC16,pop_black,pop_lat,pop_more,pop_asian,pop_aian,pop_mena,male \\\n",
    "    --t2e \\\n",
    "    --bsize 1000 \\\n",
    "    --verbose \\\n",
    "    --force-step1 \\\n",
    "    --out \"${OUTPUT_PATH}/${prefix}\"_step1_2 \\\n",
    "    --threads 16\n",
    "\n",
    "regenie \\\n",
    "    --step 2 \\\n",
    "    --bed \"${genos}/chr${chrom}\" \\\n",
    "    --extract \"${keep_snps2}\" \\\n",
    "    --keep \"${ids}\" \\\n",
    "    --phenoFile \"${pheno_file}\" \\\n",
    "    --phenoColList time \\\n",
    "    --eventColList status \\\n",
    "    --covarFile \"${cov_file}\" \\\n",
    "    --covarColList low_hdl,high_tg,high_bmi,pd_status,smoking_status,htn_status,gd_status,index_age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15,PC16,pop_black,pop_lat,pop_more,pop_asian,pop_aian,pop_mena,male \\\n",
    "    --pred \"${OUTPUT_PATH}/${prefix}\"_step1_2_pred.list \\\n",
    "    --t2e \\\n",
    "    --firth --approx \\\n",
    "    --bsize 400 \\\n",
    "    --verbose \\\n",
    "    --threads 16 \\\n",
    "    --out \"${OUTPUT_PATH}/${prefix}\"_step2_chr\"${chrom}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy script to bucket\n",
    "!gsutil cp /home/jupyter/sid_gwas_regenie.sh {my_bucket}/data/dsub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job to dsub\n",
    "%%bash --out LINE_COUNT_JOB_ID\n",
    "\n",
    "source ~/aou_dsub.bash\n",
    "\n",
    "# Get a shorter username to leave more characters for the job name.\n",
    "DSUB_USER_NAME=\"$(echo \"${OWNER_EMAIL}\" | cut -d@ -f1)\"\n",
    "\n",
    "# For AoU RWB projects network name is \"network\".\n",
    "AOU_NETWORK=network\n",
    "AOU_SUBNETWORK=subnetwork\n",
    "\n",
    "MACHINE_TYPE=\"n2-standard-4\"\n",
    "\n",
    "# Change for your bucket, path in output of cell directly above:\n",
    "BASH_SCRIPT=\"${my_bucket}/data/dsub/sid_gwas_regenie.sh\"\n",
    "\n",
    "\n",
    "# Python is 'right side limited' wherein the last value is not included\n",
    "# To run the regression across all chromosomes, set lower to 1 and upper to 23\n",
    "# To run across one chromosome, set lower to the chomosome-of-interest and upper to the following\n",
    "\n",
    "LOWER=1\n",
    "UPPER=23\n",
    "for ((chromo=$LOWER;chromo<$UPPER;chromo+=1))\n",
    "do\n",
    "\n",
    "# Choose which MAF, subset, and treatment group to run GWAS on\n",
    "MAF_name=\n",
    "subset_name=\n",
    "group_name=\n",
    "\n",
    "mnt_path=\"/mnt/data/input/gs/fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/plink_bed\"\n",
    "\n",
    "aou_dsub \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --user-project \"${GOOGLE_PROJECT}\" \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --image shinshinbooboo210/regenie_gsutil:v4.1 \\\n",
    "    --network \"${AOU_NETWORK}\" \\\n",
    "    --subnetwork \"${AOU_SUBNETWORK}\" \\\n",
    "    --service-account \"$(gcloud config get-value account)\" \\\n",
    "    --user \"${DSUB_USER_NAME}\" \\\n",
    "    --regions us-central1 \\\n",
    "    --logging \"${WORKSPACE_BUCKET}/dsub/logs/{job-name}/{user-id}/$(date +'%Y%m%d/%H%M%S')/{job-id}-{task-id}-{task-attempt}.log\" \\\n",
    "    \"$@\" \\\n",
    "    --preemptible \\\n",
    "    --disk-size 3000 \\\n",
    "    --boot-disk-size 200 \\\n",
    "    --machine-type ${MACHINE_TYPE} \\\n",
    "    --name \"${JOB_NAME}\" \\\n",
    "    --script \"${BASH_SCRIPT}\" \\\n",
    "    --env GOOGLE_PROJECT=${GOOGLE_PROJECT} \\\n",
    "    --input-recursive array_path=\"${genomic_location}/microarray/plink/\" \\\n",
    "    --input keep_snps=\"${my_bucket}/data/plink_result/qc_pass_maf${MAF_name}_${subset_name}.snplist\" \\\n",
    "    --input ids=\"${my_bucket}/sid_pheno_files/${subset_name}_ids_v2.txt\" \\\n",
    "    --input pheno_file=\"${my_bucket}/sid_pheno_files/${subset_name}_${group_name}_pheno_df.tsv\" \\\n",
    "    --input cov_file=\"${my_bucket}/sid_pheno_files/${subset_name}_${group_name}_covs_df.tsv\" \\\n",
    "    --input bed_file=\"gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/plink_bed/chr${chromo}.bed\" \\\n",
    "    --input bim_file=\"gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/plink_bed/chr${chromo}.bim\" \\\n",
    "    --input fam_file=\"gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/plink_bed/chr${chromo}.fam\" \\\n",
    "    --input keep_snps2=\"${my_bucket}/data/plink_result/snps_pass_chr${chromo}.snplist\" \\\n",
    "    --env prefix=SID_GWAS_regenie_${group_name}_${subset_name} \\\n",
    "    --env genos=\"${mnt_path}\" \\\n",
    "    --env chrom=${chromo} \\\n",
    "    --output-recursive OUTPUT_PATH=\"${my_bucket}/sid_geno_files/${group_name}_${subset_name}/\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View job status summary\n",
    "%%bash\n",
    "dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project ${GOOGLE_PROJECT} \\\n",
    "    --location us-central1 \\\n",
    "    --names \"sid-gwas-regenie\" \\\n",
    "    --users ${USER_NAME} \\\n",
    "    --status '*' | head -n 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View detailed job summary\n",
    "%%bash\n",
    "dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project ${GOOGLE_PROJECT} \\\n",
    "    --location us-central1 \\\n",
    "    --names \"sid-gwas-regenie\" \\\n",
    "    --users ${USER_NAME} \\\n",
    "    --status '*' \\\n",
    "    --full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
