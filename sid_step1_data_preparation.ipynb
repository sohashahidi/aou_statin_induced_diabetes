{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SID Genetics Study Step 1: Phenotype Preparation \n",
    "\n",
    "## Objective\n",
    "The purpose of this notebook is to assign type 2 diabetes mellitus status, find end of follow-up (EoF) dates for possible participants, and find starting eligible statin users and non-users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this section is to load packages and pull in data from the All of Us Research Project (AoURP). AoURP dataset code (R and SQL) is generated using the AoURP's cohort builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load packages and citations\n",
    "\n",
    "# install.packages('allofus')\n",
    "# install.packages('tidyverse')\n",
    "# install.packages('bigrquery')\n",
    "\n",
    "library(allofus)\n",
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "citation('allofus')\n",
    "citation('tidyverse')\n",
    "citation('bigrquery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Bring in all AoU participants\n",
    "\n",
    "# This query represents dataset \"T2D Diagnosis Redo\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_84009189_person_sql <- paste(\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        p_race_concept.concept_name as race,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `person` person \n",
    "    LEFT JOIN\n",
    "        `concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "person_84009189_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"person_84009189\",\n",
    "  \"person_84009189_*.csv\")\n",
    "message(str_glue('The data will be written to {person_84009189_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_84009189_person_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  person_84009189_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {person_84009189_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(gender = col_character(), race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_84009189_person_df <- read_bq_export_from_workspace_bucket(person_84009189_path)\n",
    "\n",
    "dim(dataset_84009189_person_df)\n",
    "\n",
    "# head(dataset_84009189_person_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Bring in glucose, fasting glucose, and HbA1c measurements\n",
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"T2D Diagnosis Redo\" for domain \"measurement\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_84009189_measurement_sql <- paste(\"\n",
    "    SELECT\n",
    "        measurement.person_id,\n",
    "        measurement.measurement_concept_id,\n",
    "        m_standard_concept.concept_name as standard_concept_name,\n",
    "        measurement.measurement_datetime,\n",
    "        measurement.value_as_number,\n",
    "        m_unit.concept_name as unit_concept_name \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `measurement` measurement \n",
    "        WHERE\n",
    "            (\n",
    "                measurement_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (3000483, 3003309, 3004410, 3004501, 3005673, 3007263, 3037110)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )) measurement \n",
    "    LEFT JOIN\n",
    "        `concept` m_standard_concept \n",
    "            ON measurement.measurement_concept_id = m_standard_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_unit \n",
    "            ON measurement.unit_concept_id = m_unit.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "measurement_84009189_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"measurement_84009189\",\n",
    "  \"measurement_84009189_*.csv\")\n",
    "message(str_glue('The data will be written to {measurement_84009189_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_84009189_measurement_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  measurement_84009189_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {measurement_84009189_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), unit_concept_name = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_84009189_measurement_df <- read_bq_export_from_workspace_bucket(measurement_84009189_path)\n",
    "\n",
    "dim(dataset_84009189_measurement_df)\n",
    "\n",
    "# head(dataset_84009189_measurement_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Type 1 diabetes medications\n",
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"T1D Medication\" for domain \"drug\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_82559853_drug_sql <- paste(\"\n",
    "    SELECT\n",
    "        d_exposure.person_id,\n",
    "        d_exposure.drug_concept_id,\n",
    "        d_standard_concept.concept_name as standard_concept_name,\n",
    "        d_exposure.drug_exposure_start_datetime,\n",
    "        d_exposure.drug_exposure_end_datetime \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `drug_exposure` d_exposure \n",
    "        WHERE\n",
    "            (\n",
    "                drug_concept_id IN (SELECT\n",
    "                    DISTINCT ca.descendant_id \n",
    "                FROM\n",
    "                    `cb_criteria_ancestor` ca \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        DISTINCT c.concept_id       \n",
    "                    FROM\n",
    "                        `cb_criteria` c       \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id             \n",
    "                        FROM\n",
    "                            `cb_criteria` cr             \n",
    "                        WHERE\n",
    "                            concept_id IN (1502905, 1513876, 1516976, 1517998, 1531601, 1544838, 1550023, 1567198, 1586346, 1596977, 19013951, 35602717, 46221581)             \n",
    "                            AND full_text LIKE '%_rank1]%'       ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) b \n",
    "                        ON (ca.ancestor_id = b.concept_id)))) d_exposure \n",
    "        LEFT JOIN\n",
    "            `concept` d_standard_concept \n",
    "                ON d_exposure.drug_concept_id = d_standard_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "drug_82559853_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"drug_82559853\",\n",
    "  \"drug_82559853_*.csv\")\n",
    "message(str_glue('The data will be written to {drug_82559853_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_82559853_drug_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  drug_82559853_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {drug_82559853_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_82559853_drug_df <- read_bq_export_from_workspace_bucket(drug_82559853_path)\n",
    "\n",
    "dim(dataset_82559853_drug_df)\n",
    "\n",
    "# head(dataset_82559853_drug_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Type 1 diabetes ICD 9 and 10 codes\n",
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"T1D ICD\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_15893752_condition_sql <- paste(\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_start_datetime,\n",
    "        c_occurrence.condition_end_datetime,\n",
    "        c_source_concept.concept_name as source_concept_name,\n",
    "        c_source_concept.concept_code as source_concept_code \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_source_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (35206878, 35206879, 44819501, 44819502, 44819504, 44820682, 44820683, 44820684, 44821787, 44822934, 44822935, 44822936, 44824071, 44825264, 44829881, 44831046, 44832190, 44832191, 44832192, 44833368, 44834549, 44836918, 45533018, 45537960, 45542736, 45547622, 45547623, 45547624, 45552379, 45552381, 45552382, 45552383, 45557110, 45566729, 45576438, 45581350, 45600636, 45600637, 45600638, 45600639, 45600640, 45605398)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 0 \n",
    "                    AND is_selectable = 1)\n",
    "            )) c_occurrence \n",
    "    LEFT JOIN\n",
    "        `concept` c_source_concept \n",
    "            ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "condition_15893752_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"condition_15893752\",\n",
    "  \"condition_15893752_*.csv\")\n",
    "message(str_glue('The data will be written to {condition_15893752_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_15893752_condition_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  condition_15893752_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {condition_15893752_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(source_concept_name = col_character(), source_concept_code = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_15893752_condition_df <- read_bq_export_from_workspace_bucket(condition_15893752_path)\n",
    "\n",
    "dim(dataset_15893752_condition_df)\n",
    "\n",
    "# head(dataset_15893752_condition_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Type 2 diabetes medications\n",
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"T2D Medication\" for domain \"drug\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_63474191_drug_sql <- paste(\"\n",
    "    SELECT\n",
    "        d_exposure.person_id,\n",
    "        d_exposure.drug_concept_id,\n",
    "        d_standard_concept.concept_name as standard_concept_name,\n",
    "        d_exposure.drug_exposure_start_datetime,\n",
    "        d_exposure.drug_exposure_end_datetime \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `drug_exposure` d_exposure \n",
    "        WHERE\n",
    "            (\n",
    "                drug_concept_id IN (SELECT\n",
    "                    DISTINCT ca.descendant_id \n",
    "                FROM\n",
    "                    `cb_criteria_ancestor` ca \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        DISTINCT c.concept_id       \n",
    "                    FROM\n",
    "                        `cb_criteria` c       \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id             \n",
    "                        FROM\n",
    "                            `cb_criteria` cr             \n",
    "                        WHERE\n",
    "                            concept_id IN (1502809, 1502826, 1503297, 1510202, 1515249, 1516766, 1518148, 1525215, 1529331, 1547504, 1559684, 1560171, 1580747, 1583722, 1594973, 1597756, 40166035, 40170911, 40239216, 43013884, 43526465, 44506754, 44785829, 44816332, 45774435, 45774751, 793143)             \n",
    "                            AND full_text LIKE '%_rank1]%'       ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) b \n",
    "                        ON (ca.ancestor_id = b.concept_id)))) d_exposure \n",
    "        LEFT JOIN\n",
    "            `concept` d_standard_concept \n",
    "                ON d_exposure.drug_concept_id = d_standard_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "drug_63474191_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"drug_63474191\",\n",
    "  \"drug_63474191_*.csv\")\n",
    "message(str_glue('The data will be written to {drug_63474191_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_63474191_drug_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  drug_63474191_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {drug_63474191_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_63474191_drug_df <- read_bq_export_from_workspace_bucket(drug_63474191_path)\n",
    "\n",
    "dim(dataset_63474191_drug_df)\n",
    "\n",
    "# head(dataset_63474191_drug_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Type 2 diabetes ICD 9 and 10 codes\n",
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"T2D ICD\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_95475017_condition_sql <- paste(\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_start_datetime,\n",
    "        c_occurrence.condition_end_datetime,\n",
    "        c_source_concept.concept_name as source_concept_name,\n",
    "        c_source_concept.concept_code as source_concept_code \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_source_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (35206881, 35206882, 44819500, 44824073, 44826460, 44826461, 44827616, 44827617, 44828795, 44829879, 44829882, 44831045, 44831047, 44832193, 44832194, 44833366, 44833367, 44836914, 44836915, 44836916, 45533019, 45533021, 45533023, 45542738, 45547626, 45547627, 45561949, 45566731, 45581352, 45581353, 45581355, 45586139, 45586140, 45591027, 45591031, 45595798, 45595799, 45600642, 45605401, 45605403, 45605405)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 0 \n",
    "                    AND is_selectable = 1)\n",
    "            )) c_occurrence \n",
    "    LEFT JOIN\n",
    "        `concept` c_source_concept \n",
    "            ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "condition_95475017_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"condition_95475017\",\n",
    "  \"condition_95475017_*.csv\")\n",
    "message(str_glue('The data will be written to {condition_95475017_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_95475017_condition_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  condition_95475017_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {condition_95475017_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(source_concept_name = col_character(), source_concept_code = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_95475017_condition_df <- read_bq_export_from_workspace_bucket(condition_95475017_path)\n",
    "\n",
    "dim(dataset_95475017_condition_df)\n",
    "\n",
    "# head(dataset_95475017_condition_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Rename and check AoU generated data sets\n",
    "all_person <- dataset_84009189_person_df\n",
    "length(unique(all_person$person_id))\n",
    "dim(all_person)\n",
    "# head(all_person)\n",
    "\n",
    "all_diabetes_meas <- dataset_84009189_measurement_df\n",
    "length(unique(all_diabetes_meas$person_id))\n",
    "dim(all_diabetes_meas)\n",
    "# head(all_diabetes_meas)\n",
    "\n",
    "t1d_drug <- dataset_82559853_drug_df\n",
    "length(unique(t1d_drug$person_id))\n",
    "dim(t1d_drug)\n",
    "# head(t1d_drug)\n",
    "\n",
    "t1d_icd <- dataset_15893752_condition_df\n",
    "length(unique(t1d_icd$person_id))\n",
    "dim(t1d_icd)\n",
    "# head(t1d_icd)\n",
    "\n",
    "t2d_drug <- dataset_63474191_drug_df\n",
    "length(unique(t2d_drug$person_id))\n",
    "dim(t2d_drug)\n",
    "# head(t2d_drug)\n",
    "\n",
    "t2d_icd <- dataset_95475017_condition_df\n",
    "length(unique(t2d_icd$person_id))\n",
    "dim(t2d_icd)\n",
    "# head(t2d_icd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# All of Us Death dataframe\n",
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"EOF Data Frame\" for domain \"death\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_95436229_death_sql <- paste(\"\n",
    "    SELECT\n",
    "        death.person_id, \n",
    "        death.death_date, \n",
    "        death.death_datetime, \n",
    "        death.death_type_concept_id, \n",
    "        death.cause_concept_id, \n",
    "        death.cause_source_value, \n",
    "        death.cause_source_concept_id \n",
    "    FROM\n",
    "        `death` death\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "death_95436229_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"death_95436229\",\n",
    "  \"death_95436229_*.csv\")\n",
    "message(str_glue('The data will be written to {death_95436229_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_95436229_death_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  death_95436229_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {person_97344176_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(cause_source_value = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_95436229_death_df <- read_bq_export_from_workspace_bucket(death_95436229_path)\n",
    "\n",
    "dim(dataset_95436229_death_df)\n",
    "\n",
    "# head(dataset_95436229_death_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Statin data frame\n",
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"Statins\" for domain \"drug\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_97634019_drug_sql <- paste(\"\n",
    "    SELECT\n",
    "        d_exposure.person_id,\n",
    "        d_standard_concept.concept_name as standard_concept_name,\n",
    "        d_exposure.drug_exposure_start_datetime,\n",
    "        d_exposure.drug_exposure_end_datetime,\n",
    "        d_type.concept_name as drug_type_concept_name,\n",
    "        d_source_concept.concept_name as source_concept_name \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `drug_exposure` d_exposure \n",
    "        WHERE\n",
    "            (\n",
    "                drug_concept_id IN (SELECT\n",
    "                    DISTINCT ca.descendant_id \n",
    "                FROM\n",
    "                    `cb_criteria_ancestor` ca \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        DISTINCT c.concept_id       \n",
    "                    FROM\n",
    "                        `cb_criteria` c       \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id             \n",
    "                        FROM\n",
    "                            `cb_criteria` cr             \n",
    "                        WHERE\n",
    "                            concept_id IN (1510813, 1539403, 1545958, 1549686, 1551860, 1592085, 1592180, 40165636)             \n",
    "                            AND full_text LIKE '%_rank1]%'       ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) b \n",
    "                        ON (ca.ancestor_id = b.concept_id)))) d_exposure \n",
    "        LEFT JOIN\n",
    "            `concept` d_standard_concept \n",
    "                ON d_exposure.drug_concept_id = d_standard_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `concept` d_type \n",
    "                ON d_exposure.drug_type_concept_id = d_type.concept_id \n",
    "        LEFT JOIN\n",
    "            `concept` d_source_concept \n",
    "                ON d_exposure.drug_source_concept_id = d_source_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "drug_97634019_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"drug_97634019\",\n",
    "  \"drug_97634019_*.csv\")\n",
    "message(str_glue('The data will be written to {drug_97634019_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_97634019_drug_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  drug_97634019_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n",
    "\n",
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {drug_97634019_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), drug_type_concept_name = col_character(), source_concept_name = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_97634019_drug_df <- read_bq_export_from_workspace_bucket(drug_97634019_path)\n",
    "\n",
    "dim(dataset_97634019_drug_df)\n",
    "\n",
    "# head(dataset_97634019_drug_df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing T2D Diagnosis Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this section is to determine the type 2 diabetes mellitus (T2D) status of participants in AoU, using Northwestern University's Type 2 Diabetes Mellitus diagnosis algorithm: https://phekb.org/phenotype/type-2-diabetes-mellitus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create DF where particpants have at least one T2D diagnosis code\n",
    "t2d_icd_status <- t2d_icd %>%\n",
    "                group_by(person_id) %>%\n",
    "                arrange(person_id, condition_start_datetime) %>%\n",
    "                mutate(t2d_icd = 1) %>%\n",
    "                slice_head() %>%\n",
    "                rename(start_date = condition_start_datetime) %>%\n",
    "                mutate(reason = \"t2d icd\",\n",
    "                      value = NA) %>%\n",
    "                select(person_id, start_date, reason, value, t2d_icd) %>%\n",
    "                distinct(.keep_all = TRUE)\n",
    "\n",
    "length(unique(t2d_icd_status$person_id))\n",
    "dim(t2d_icd_status)\n",
    "# head(t2d_icd_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create DF where particpants have at least 2 T2D diagnoses on different dates\n",
    "t2d_icd2_status <- t2d_icd %>% \n",
    "                group_by(person_id) %>% \n",
    "                filter(n() >= 2) %>% \n",
    "                filter(n_distinct(condition_start_datetime) >= 2) %>%\n",
    "                arrange(person_id, condition_start_datetime) %>%\n",
    "                mutate(t2d_icd_2x = 1) %>% \n",
    "                slice_head() %>%\n",
    "                rename(start_date = condition_start_datetime) %>%\n",
    "                mutate(reason = \"t2d icd x2\",\n",
    "                      value = NA) %>%\n",
    "                select(person_id, start_date, reason, value, t2d_icd_2x) %>%\n",
    "                distinct(.keep_all = TRUE)\n",
    "\n",
    "length(unique(t2d_icd2_status$person_id))\n",
    "dim(t2d_icd2_status)\n",
    "# head(t2d_icd2_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create DF where participants have at least one abnormal lab value\n",
    "t2d_lab_status <- all_diabetes_meas %>% \n",
    "                group_by(person_id) %>% \n",
    "                mutate(lab_status = ifelse((measurement_concept_id == 3000483 & value_as_number > 200) |\n",
    "                                          (measurement_concept_id == 3004501 & value_as_number > 200) |\n",
    "                                          (measurement_concept_id == 3037110 & value_as_number >= 125) |\n",
    "                                          (measurement_concept_id == 3004410 & value_as_number >= 6.5) |\n",
    "                                          (measurement_concept_id == 3007263 & value_as_number >= 6.5) |\n",
    "                                          (measurement_concept_id == 3003309 & value_as_number >= 6.5) |\n",
    "                                          (measurement_concept_id == 3005673 & value_as_number >= 6.5), 1, 0)) %>%\n",
    "                arrange(person_id, measurement_datetime) %>%\n",
    "                filter(lab_status == 1) %>%\n",
    "                slice_head() %>%\n",
    "                rename(start_date = measurement_datetime,\n",
    "                      value = value_as_number,\n",
    "                      reason = measurement_concept_id) %>%\n",
    "                mutate(reason = as.character(reason)) %>%\n",
    "                select(person_id, start_date, reason, value, lab_status) %>%\n",
    "                distinct(.keep_all = TRUE)\n",
    "\n",
    "length(unique(t2d_lab_status$person_id))\n",
    "dim(t2d_lab_status)\n",
    "# head(t2d_lab_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create DF where participants have taken at least one T1D medication\n",
    "t1d_drug_status <- t1d_drug %>% \n",
    "                group_by(person_id) %>% \n",
    "                arrange(person_id, drug_exposure_start_datetime) %>%\n",
    "                mutate(t1d_drug = 1) %>% \n",
    "                slice_head() %>%\n",
    "                rename(start_date = drug_exposure_start_datetime) %>%\n",
    "                mutate(reason = \"t2d rx\",\n",
    "                      value = NA) %>%\n",
    "                select(person_id, start_date, reason, value, t1d_drug) %>%\n",
    "                distinct(.keep_all = TRUE)\n",
    "\n",
    "length(unique(t1d_drug_status$person_id))\n",
    "dim(t1d_drug_status)\n",
    "# head(t1d_drug_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create DF where participants have taken at least one T2D medication\n",
    "t2d_drug_status <- t2d_drug %>% \n",
    "                group_by(person_id) %>% \n",
    "                arrange(person_id, drug_exposure_start_datetime) %>%\n",
    "                mutate(t2d_drug = 1) %>% \n",
    "                slice_head() %>%\n",
    "                rename(start_date = drug_exposure_start_datetime) %>%\n",
    "                mutate(reason = \"t2d rx\",\n",
    "                      value = NA) %>%\n",
    "                select(person_id, start_date, reason, value, t2d_drug) %>%\n",
    "                distinct(.keep_all = TRUE)\n",
    "\n",
    "length(unique(t2d_drug_status$person_id))\n",
    "dim(t2d_drug_status)\n",
    "# head(t2d_drug_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create DF where particpants have at least one T1D diagnosis\n",
    "t1d_icd_status <- t1d_icd %>% \n",
    "                group_by(person_id) %>% \n",
    "                arrange(person_id, condition_start_datetime) %>%\n",
    "                mutate(t1d_icd = 1) %>% \n",
    "                slice_head() %>%\n",
    "                rename(start_date = condition_start_datetime) %>%\n",
    "                mutate(reason = \"t1d icd\",\n",
    "                      value = NA) %>%\n",
    "                select(person_id, start_date, reason, value, t1d_icd) %>%\n",
    "                distinct(.keep_all = TRUE)\n",
    "\n",
    "length(unique(t1d_icd_status$person_id))\n",
    "dim(t1d_icd_status)\n",
    "# head(t1d_icd_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Rename start date and join T1D and T2D drug data frames\n",
    "rename_drug_status <- t1d_drug_status %>% \n",
    "                        rename(start_date_t1d = start_date) %>%\n",
    "                        right_join(t2d_drug_status)\n",
    "\n",
    "length(unique(rename_drug_status$person_id))\n",
    "dim(rename_drug_status)\n",
    "head(rename_drug_status)\n",
    "\n",
    "# Create DF where participants have taken 2+ T1D or T2D drugs with T2D exposure occuring ≥1 day before T1D\n",
    "t2d_before_t1d_drug <- rename_drug_status %>%\n",
    "                            filter(!is.na(start_date_t1d) & \n",
    "                                   as.numeric(difftime(as.Date(start_date_t1d), as.Date(start_date),\n",
    "                                                      units = \"days\")) >= 1) %>%\n",
    "                            mutate(t2d_before_t1d_drug = 1) %>%\n",
    "                            mutate(reason = \"t2d rx before t1d rx\",\n",
    "                                    value = NA) %>%\n",
    "                            select(person_id, start_date, reason, value, t2d_before_t1d_drug)\n",
    "\n",
    "length(unique(t2d_before_t1d_drug$person_id))\n",
    "dim(t2d_before_t1d_drug)\n",
    "# head(t2d_before_t1d_drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Join all parts of the diagnosis algorithm into one data frame\n",
    "t2d_determination_df <- full_join(t2d_drug_status, t1d_drug_status) %>%\n",
    "                        full_join(t2d_icd_status) %>%\n",
    "                        full_join(t2d_icd2_status) %>%\n",
    "                        full_join(t2d_lab_status) %>%\n",
    "                        full_join(t1d_icd_status) %>%\n",
    "                        full_join(t2d_before_t1d_drug) %>% \n",
    "                        arrange(person_id, start_date) %>%\n",
    "                        mutate(across(c(t2d_drug,t1d_drug,t2d_icd,t2d_icd_2x,lab_status,t1d_icd,t2d_before_t1d_drug), function(x) ifelse(is.na(x), 0, 1))) %>%\n",
    "                        distinct(.keep_all = TRUE)\n",
    "\n",
    "length(unique(t2d_determination_df$person_id))\n",
    "dim(t2d_determination_df)\n",
    "# head(t2d_determination_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check counts for all parts of the diagnosis algorithm\n",
    "print(\"t2d_drug\")\n",
    "table(t2d_determination_df$t2d_drug, useNA = \"always\")\n",
    "\n",
    "print(\"t1d_drug\")\n",
    "table(t2d_determination_df$t1d_drug, useNA = \"always\")\n",
    "\n",
    "print(\"t2d_icd\")\n",
    "table(t2d_determination_df$t2d_icd, useNA = \"always\")\n",
    "\n",
    "print(\"t2d_icd_2x\")\n",
    "table(t2d_determination_df$t2d_icd_2x, useNA = \"always\")\n",
    "\n",
    "print(\"lab_status\")\n",
    "table(t2d_determination_df$lab_status, useNA = \"always\")\n",
    "\n",
    "print(\"t1d_icd\")\n",
    "table(t2d_determination_df$t1d_icd, useNA = \"always\")\n",
    "\n",
    "print(\"t2d_before_t1d_drug\")\n",
    "table(t2d_determination_df$t2d_before_t1d_drug, useNA = \"always\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Exclude T1D cases and label each case in order\n",
    "t2d_cases_df <- t2d_determination_df %>% group_by(person_id) %>% \n",
    "                filter(t1d_icd == 0) %>%\n",
    "                mutate(case = case_when(any(t2d_icd == 1) & any(t2d_drug == 1) & any(t1d_drug == 0) ~ 1,\n",
    "                                        any(t2d_icd == 1) & any(t2d_before_t1d_drug == 1) ~ 2,\n",
    "                                        any(t2d_icd_2x == 1) & any(t1d_drug == 1) ~ 3,\n",
    "                                        (any(t2d_drug == 1) | any(t2d_icd == 1)) & any(lab_status == 1) ~ 4))\n",
    "                       \n",
    "table(t2d_cases_df$case, useNA = \"always\")\n",
    "length(unique(t2d_cases_df$person_id))\n",
    "dim(t2d_cases_df)\n",
    "# head(t2d_cases_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get the first date of potential T2D diagnosis\n",
    "t2d_cases_df_counts <- t2d_cases_df %>% select(person_id, start_date, reason, value, case) %>%\n",
    "                        group_by(person_id) %>%\n",
    "                        arrange(person_id, start_date) %>%\n",
    "                        slice_head()\n",
    "\n",
    "table(t2d_cases_df_counts$case, useNA = \"always\")\n",
    "length(unique(t2d_cases_df_counts$person_id))\n",
    "dim(t2d_cases_df_counts)\n",
    "# head(t2d_cases_df_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Remove non-cases (NA)\n",
    "t2d_cases_df_final <- t2d_cases_df_counts %>% filter(!is.na(case))\n",
    "\n",
    "table(t2d_cases_df_final$case, useNA = \"always\")\n",
    "length(unique(t2d_cases_df_final$person_id))\n",
    "dim(t2d_cases_df_final)\n",
    "# head(t2d_cases_df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining End of Follow Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this notebook is to determine either the event date (date of T2D diagnosis) or right-censor date (date of last fasting glucose, random glucose, or HbA1c measurement or date of death) for participants in AoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get all diabetes-related measures and arrange them by date to get the last one\n",
    "all_diabetes_meas_eof <- all_diabetes_meas %>% select(person_id, measurement_datetime) %>% \n",
    "                            group_by(person_id) %>%\n",
    "                            arrange(person_id, measurement_datetime) %>%\n",
    "                            slice_tail()\n",
    "\n",
    "length(unique(all_diabetes_meas_eof$person_id))\n",
    "dim(all_diabetes_meas_eof)\n",
    "# head(all_diabetes_meas_eof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get the date of death for deceased patients (if multiple, get the latest)\n",
    "death_eof <- dataset_95436229_death_df %>% select(person_id, death_datetime)%>% \n",
    "                            group_by(person_id) %>%\n",
    "                            arrange(person_id, death_datetime) %>%\n",
    "                            slice_tail()\n",
    "\n",
    "length(unique(death_eof$person_id))\n",
    "dim(death_eof)\n",
    "# head(death_eof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get the date of diabetes diagnosis for participants with T2D (from previous section)\n",
    "t2d_cases_df_eof <- t2d_cases_df_final %>% select(person_id, start_date)\n",
    "\n",
    "length(unique(t2d_cases_df_eof$person_id))\n",
    "dim(t2d_cases_df_eof)\n",
    "# head(t2d_cases_df_eof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine potention EoF dates into one data frame\n",
    "# Choose T2D diagnosis if available\n",
    "# Choose death date if after measurement date and both are available\n",
    "# Label events and censored participants\n",
    "# Calculate EoF age\n",
    "\n",
    "eof_df <- full_join(all_person, all_diabetes_meas_eof) %>%\n",
    "            full_join(death_eof) %>%\n",
    "            full_join(t2d_cases_df_eof) %>%\n",
    "            filter(!(is.na(measurement_datetime) & is.na(death_datetime) & is.na(start_date))) %>%\n",
    "            mutate(eof_datetime = ifelse(!is.na(start_date), start_date, \n",
    "                                         ifelse(is.na(death_datetime), measurement_datetime, \n",
    "                                               ifelse(is.na(measurement_datetime), death_datetime,\n",
    "                                                     ifelse(as.Date(death_datetime) >= as.Date(measurement_datetime),\n",
    "                                                          death_datetime, measurement_datetime))))) %>%\n",
    "            mutate(t2d_status = ifelse(!is.na(start_date), \"Event\", \"Censor\"),\n",
    "                  eof_age = round(as.numeric(difftime(as.Date(eof_datetime), as.Date(date_of_birth), \n",
    "                                                      units = \"days\"))/365.2425, digits = 1)) %>%\n",
    "            select(person_id, date_of_birth, eof_datetime, eof_age, t2d_status)\n",
    "            \n",
    "\n",
    "length(unique(eof_df$person_id))\n",
    "dim(eof_df)\n",
    "# head(eof_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check EoF age for censored vs. event participants by generating summary statistics and a box plot\n",
    "boxplot(eof_age ~ t2d_status, data = eof_df, col = c(\"coral\", \"lightblue\"))\n",
    "eof_df %>% group_by(t2d_status) %>% summarize(\n",
    "                                        Count = n(),\n",
    "                                        Min = min(eof_age, na.rm = TRUE),\n",
    "                                        \"1st Qu.\" = quantile(eof_age, na.rm = TRUE)[[\"25%\"]],\n",
    "                                        Median = median(eof_age, na.rm = TRUE),\n",
    "                                        Mean = mean(eof_age, na.rm = TRUE), \n",
    "                                        SD = sd(eof_age, na.rm = TRUE),\n",
    "                                        \"3rd Qu.\" = quantile(eof_age, na.rm = TRUE)[[\"75%\"]],\n",
    "                                        Max = max(eof_age, na.rm = TRUE),\n",
    "                                        \"NA's\" = sum(is.na(eof_age)))\n",
    "                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Eligible Statin Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this section is to find statin users in AoU meeting eligibility criteria for this study. Eligibility criteria is as follows:\n",
    "- At least one statin prescription\n",
    "- At least 30 days of follow-up after starting statins (to give enough time for NOD to possibly develop)\n",
    "- At least 6 months (180 days) of follow-up before starting statins (to verify that the statin initiation date is the first time receiving statins)\n",
    "\n",
    "The first prescribed statin type and dosage for each eligible statin user was also extracted. Since this study is designed on an intention-to-treat basis, the first prescription was assumed to be carried throughout the rest of the study period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Find starting number of eligible statin users and filter out any Rx that occur after EoF\n",
    "statin_rx <- inner_join(eof_df, dataset_97634019_drug_df) %>%\n",
    "                filter(as.Date(drug_exposure_start_datetime) < as.Date(eof_datetime))\n",
    "\n",
    "length(unique(statin_rx$person_id))\n",
    "dim(statin_rx)\n",
    "# head(statin_rx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to extract statin dose from standard concept name\n",
    "library(stringr)\n",
    "extract_dose <- function(x) {\n",
    "    split_drug <- ifelse(grepl(\"/\", x), strsplit(x, \"/\"), x) # checks if drug concept name has a '/', \n",
    "    # which means it's a combo drug and splits it into a list if so\n",
    "    statin_part <- NULL # initializes a variable to hold the statin containing part of the drug name\n",
    "    for (i in 1:length(split_drug[[1]])) { # loops through the list of drug parts\n",
    "        if (grepl(\"statin\", split_drug[[1]][i])) { # checks if drug part contains the string 'statin'\n",
    "            if (!is.null(statin_part)) stop(\"Whoops; detected more than one statin\") # checks if the previous loop \n",
    "            # also found a statin and throws an error if so, meant to protect against multiple statins in one combo\n",
    "            statin_part <- split_drug[[1]][which(grepl(\"statin\", split_drug[[1]]))] # assigns the part of the combo\n",
    "            # drug with a statin to the 'statin_part' variable\n",
    "        }\n",
    "    }\n",
    "    if (length(statin_part) != 1) return(NA) # throws an error if the length of \n",
    "    # statin_part is not one\n",
    "    \n",
    "    if (is.null(statin_part)) return(NA) # returns NA if there is no dose\n",
    "\n",
    "    dose <- str_extract_all(statin_part, \"[[:digit:]\\\\.]+ MG\") # extracts the dosage from the statin part\n",
    "    dose <- unlist(dose) # unlists the dose so it can be a character vector instead\n",
    "    stopifnot(is.character(dose)) # makes sure the last step worked\n",
    "    if (length(dose) == 0) return(NA) # checks again for no dose and returns NA\n",
    "    \n",
    "    return(dose) # returns the dose\n",
    "}\n",
    "\n",
    "# extract_dose(statin_rx[[33, \"standard_concept_name\"]])\n",
    "# class(statin_rx[[33, \"standard_concept_name\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate statin initiation age and find starting statin type + dose\n",
    "statin_init <- statin_rx %>% group_by(person_id) %>% \n",
    "                arrange(person_id, drug_exposure_start_datetime) %>%\n",
    "                slice_head() %>%\n",
    "                mutate(statin_init_date = drug_exposure_start_datetime,\n",
    "                      statin_init_age = round(as.numeric(difftime(as.Date(statin_init_date), as.Date(date_of_birth), \n",
    "                                                      units = \"days\"))/365.2425, digits = 1),\n",
    "                      statin_type_start = str_extract(standard_concept_name, pattern = \"[:alpha:]+statin\"),\n",
    "                      statin_dose_start = extract_dose(standard_concept_name)) %>%\n",
    "                select(person_id, statin_init_date, statin_init_age, statin_type_start, statin_dose_start)\n",
    "\n",
    "length(unique(statin_init$person_id))\n",
    "dim(statin_init)\n",
    "# head(statin_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Find last statin prescription, start and end date, and type + dose\n",
    "statin_end <- statin_rx %>% group_by(person_id) %>% \n",
    "                arrange(person_id, drug_exposure_end_datetime) %>%\n",
    "                slice_tail() %>%\n",
    "                mutate(statin_end_date = ifelse(as.Date(drug_exposure_start_datetime) == as.Date(drug_exposure_end_datetime) |\n",
    "                                              is.na(drug_exposure_end_datetime), \n",
    "                                              as.character(as.Date(drug_exposure_start_datetime) + 1),\n",
    "                                              as.character(as.Date(drug_exposure_end_datetime))),\n",
    "                      statin_end_age = round(as.numeric(difftime(as.Date(statin_end_date), as.Date(date_of_birth), \n",
    "                                                      units = \"days\"))/365.2425, digits = 1)) %>%\n",
    "                mutate(statin_type_end = str_extract(standard_concept_name, pattern = \"[:alpha:]+statin\"),\n",
    "                      statin_dose_end = extract_dose(standard_concept_name)) %>%\n",
    "                select(person_id, statin_end_date, statin_end_age, statin_type_end, statin_dose_end) %>% \n",
    "                full_join(statin_init)\n",
    "\n",
    "length(unique(statin_end$person_id))\n",
    "dim(statin_end)\n",
    "# head(statin_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Add statin init age, date, type, and dose to statin rx df, then:\n",
    "    # Assign Rx IDs\n",
    "    # Add 1 day to Rx which only have start dates\n",
    "    # Calculate start + end ages\n",
    "    # Calculate days supply\n",
    "statin_rx_df <- full_join(statin_rx, statin_end) %>% \n",
    "                    group_by(person_id) %>%\n",
    "                    arrange(person_id, drug_exposure_start_datetime) %>%\n",
    "                    mutate(new_rx_end = ifelse(as.Date(drug_exposure_start_datetime) == as.Date(drug_exposure_end_datetime) |\n",
    "                                              is.na(drug_exposure_end_datetime), \n",
    "                                              as.character(as.Date(drug_exposure_start_datetime) + 1),\n",
    "                                              as.character(as.Date(drug_exposure_end_datetime)))) %>%\n",
    "                    mutate(rx_start_age = round(as.numeric(difftime(as.Date(drug_exposure_start_datetime), as.Date(date_of_birth), \n",
    "                                                      units = \"days\"))/365.2425, digits = 1),\n",
    "                           rx_end_age = round(as.numeric(difftime(as.Date(new_rx_end), as.Date(date_of_birth), \n",
    "                                                      units = \"days\"))/365.2425, digits = 1),\n",
    "                           rx_days_supply = round(as.numeric(difftime(as.Date(new_rx_end), as.Date(drug_exposure_start_datetime), \n",
    "                                                      units = \"days\")), digits = 1),\n",
    "                          rx_id = paste0(\"RX\", 1:length(person_id))) %>% \n",
    "                    select(person_id, date_of_birth, eof_datetime, eof_age, t2d_status, statin_init_date, \n",
    "                           statin_init_age, statin_type_start, statin_dose_start, rx_id, \n",
    "                           drug_exposure_start_datetime, rx_start_age, new_rx_end, rx_end_age, statin_end_date, \n",
    "                           statin_end_age, statin_type_end, statin_dose_end, rx_days_supply) %>%\n",
    "                    rename(rx_start_date = drug_exposure_start_datetime,\n",
    "                          rx_end_date = new_rx_end)\n",
    "                    \n",
    "\n",
    "length(unique(statin_rx_df$person_id))\n",
    "dim(statin_rx_df)\n",
    "# head(statin_rx_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to calculate total time while considering overlaps - Code provided by lab member\n",
    "calculate_total_time <- function(data) {\n",
    "    \n",
    "    # Sort data by start date\n",
    "    data <-  data %>% arrange(rx_start_date)\n",
    "    \n",
    "    # Initialize variables\n",
    "    sum <- 0\n",
    "    prev_start <- NULL\n",
    "    prev_end <- NULL\n",
    "    \n",
    "    for (i in 1:nrow(data)) {\n",
    "        current_start <- data$rx_start_date[i]\n",
    "        current_end <- data$new_rx_end_date[i]\n",
    "        \n",
    "        if (current_start <= data$new_rx_end_date[i]) {\n",
    "            if (is.null(prev_start)) {\n",
    "            prev_start <- current_start\n",
    "            prev_end <- current_end\n",
    "            } else if (current_start > prev_end) {\n",
    "            sum <- sum + as.numeric(difftime(prev_end, prev_start, units = \"days\"))\n",
    "            prev_start <- current_start\n",
    "            prev_end <- current_end\n",
    "            } else if (current_end > prev_end) {\n",
    "            prev_end <- current_end\n",
    "        }\n",
    "       }\n",
    "    }\n",
    "    \n",
    "    if(!is.null(prev_start)) {\n",
    "        sum <- sum + as.numeric(difftime(prev_end, prev_start, units = \"days\"))\n",
    "    }\n",
    "    \n",
    "    return(sum)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate observation period table for eligible statin user cohort\n",
    "library(allofus)\n",
    "\n",
    "con <- aou_connect()\n",
    "\n",
    "# create observation_period table for everyone\n",
    "su_observation_period_tbl <- aou_observation_period(cohort = statin_rx_df, collect = TRUE)\n",
    "su_observation_period_tbl$person_id <- as.integer(su_observation_period_tbl$person_id)\n",
    "\n",
    "dim(su_observation_period_tbl)\n",
    "# head(su_observation_period_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a data frame with statin users meeting minimum conditions (enough follow-up and enough pre-follow-up)\n",
    "statin_rx_df_c <- full_join(statin_rx_df, su_observation_period_tbl) %>% group_by(person_id) %>%\n",
    "                    mutate(follow_up_time_1 = as.numeric(difftime(as.Date(eof_datetime), \n",
    "                                                                 as.Date(statin_init_date), \n",
    "                                                                 units = 'days')),\n",
    "                            enough_followup = ifelse(follow_up_time_1 >= 30, 1, 0), \n",
    "                            pre_followup = as.numeric(difftime(as.Date(statin_init_date), \n",
    "                                                               observation_period_start_date, units = \"days\")),\n",
    "                            enough_pre_followup = ifelse(pre_followup > 180, 1, 0)) \n",
    "\n",
    "statin_rx_df_itt <- statin_rx_df_c %>%\n",
    "                      filter(enough_followup == 1 & enough_pre_followup == 1)\n",
    "\n",
    "length(unique(statin_rx_df_itt$person_id))\n",
    "dim(statin_rx_df_itt)\n",
    "# head(statin_rx_df_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Remove prescription data to get data frame of distinct statin users\n",
    "statin_rx_df_itt_distinct <- statin_rx_df_itt %>% select(-c('rx_id', 'rx_start_date', 'rx_start_age',\n",
    "                                                            'rx_end_date', 'rx_end_age', 'rx_days_supply',\n",
    "                                                            'observation_period_start_date', \n",
    "                                                            'observation_period_end_date', 'follow_up_time_1',\n",
    "                                                            'pre_followup','enough_pre_followup')) %>%\n",
    "                                                    distinct(.keep_all = TRUE)\n",
    "\n",
    "length(unique(statin_rx_df_itt_distinct$person_id))\n",
    "dim(statin_rx_df_itt_distinct)\n",
    "# head(statin_rx_df_itt_distinct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Save eligible statin user df into workspace bucket\n",
    "my_bucket <- Sys.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "write.csv(statin_rx_df_itt_distinct, \"statin_rx_df_v2_distinct.csv\")\n",
    "system(paste0(\"gsutil cp ./\", \"statin_rx_df_v2_distinct.csv\", \" \", my_bucket, \"/sid_pheno_files/\"), intern=T)\n",
    "\n",
    "write.csv(statin_rx_df_itt, \"statin_rx_df_v2_rx.csv\")\n",
    "system(paste0(\"gsutil cp ./\", \"statin_rx_df_v2_rx.csv\", \" \", my_bucket, \"/sid_pheno_files/\"), intern=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Eligible Non-users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: The purpose of this section is to find participants in AoU who have either never taken statins or have started statins with less than 30 days of follow-up afterward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Find eligible non-users from EoF df\n",
    "non_users_eof_df <- left_join(eof_df, statin_rx_df_itt_distinct) %>% \n",
    "                        filter(is.na(statin_init_age) | enough_followup == 0) %>%\n",
    "                        select(person_id, date_of_birth, eof_datetime, eof_age, t2d_status)\n",
    "                        \n",
    "\n",
    "length(unique(non_users_eof_df$person_id))\n",
    "dim(non_users_eof_df)\n",
    "# head(non_users_eof_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Count event status in non-users vs. statin users\n",
    "nu_table <- table(non_users_eof_df$t2d_status, useNA = \"always\")\n",
    "su_table <- table(statin_rx_df_itt_distinct$t2d_status, useNA = \"always\")\n",
    "\n",
    "print(\"Non-users\")\n",
    "nu_table\n",
    "prop.table(nu_table)\n",
    "\n",
    "print(\"Statin Users\")\n",
    "su_table\n",
    "prop.table(su_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Save eligible non-user df into workspace bucket\n",
    "write.csv(non_users_eof_df, \"non_users_eof_df_v2.csv\")\n",
    "system(paste0(\"gsutil cp ./\", \"non_users_eof_df_v2.csv\", \" \", my_bucket, \"/sid_pheno_files/\"), intern=T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
